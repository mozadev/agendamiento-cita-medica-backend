# ğŸ ExplicaciÃ³n del Workflow de Deploy - LÃ­nea por LÃ­nea

## ğŸ“‹ Ãndice
1. [ConfiguraciÃ³n General (LÃ­neas 1-27)](#1-configuraciÃ³n-general)
2. [Job: Test and Build (LÃ­neas 33-84)](#2-job-test-and-build)
3. [Job: Deploy Terraform (LÃ­neas 88-915)](#3-job-deploy-terraform)
4. [Job: Deploy SAM (LÃ­neas 919-1295)](#4-job-deploy-sam)
5. [Job: Init Databases (LÃ­neas 1299-1339)](#5-job-init-databases)
6. [Job: Integration Tests (LÃ­neas 1344-1389)](#6-job-integration-tests)
7. [Job: Notify (LÃ­neas 1394-1418)](#7-job-notify)

---

## 1. ConfiguraciÃ³n General (LÃ­neas 1-27)

### LÃ­neas 1-2: Nombre del Workflow
```yaml
name: Deploy Infrastructure and Application
```
**ğŸ Simple**: Es como ponerle un nombre a una receta. Cuando veas este workflow en GitHub Actions, verÃ¡s este nombre.
 
**ğŸ”§ TÃ©cnico**: Define el nombre visible del workflow en la interfaz de GitHub Actions.

---

### LÃ­neas 3-22: Triggers (CuÃ¡ndo se ejecuta)
```yaml
on:
  push:
    branches:
      - main
      - develop
  pull_request:
    branches:
      - main
      - develop
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment to deploy'
        required: true
        default: 'dev'
        type: choice
        options:
          - dev
          - staging
          - prod
```

**ğŸ Simple**: 
- `push`: Se ejecuta automÃ¡ticamente cuando alguien hace push a `main` o `develop` (como cuando guardas un archivo y lo subes)
- `pull_request`: Se ejecuta cuando alguien crea un PR hacia `main` o `develop` (para verificar que todo funciona antes de fusionar)
- `workflow_dispatch`: Te permite ejecutarlo manualmente desde GitHub, eligiendo el ambiente (dev/staging/prod)

**ğŸ”§ TÃ©cnico**:
- `on.push`: Trigger automÃ¡tico basado en eventos de Git push
- `on.pull_request`: Trigger para validaciones en PRs (CI)
- `on.workflow_dispatch`: Permite ejecuciÃ³n manual con inputs interactivos
- `inputs`: Define parÃ¡metros que el usuario puede elegir al ejecutar manualmente

---

### LÃ­neas 24-27: Variables de Entorno Globales
```yaml
env:
  AWS_REGION: us-east-1
  NODE_VERSION: '20'
  TERRAFORM_VERSION: '1.6.0'
```

**ğŸ Simple**: Son como "configuraciones globales" que todos los jobs pueden usar. Es como tener un cuaderno con informaciÃ³n que todos pueden leer.

**ğŸ”§ TÃ©cnico**: Variables de entorno disponibles en todos los jobs del workflow. Evita repetir valores y facilita el mantenimiento.

---

## 2. Job: Test and Build (LÃ­neas 33-84)

### LÃ­neas 33-35: DefiniciÃ³n del Job
```yaml
test-and-build:
  name: Test and Build
  runs-on: ubuntu-latest
```

**ğŸ Simple**: Es como contratar a un trabajador llamado "Test and Build" que trabaja en una mÃ¡quina Ubuntu (Linux).

**ğŸ”§ TÃ©cnico**: Define un job que se ejecuta en un runner de GitHub Actions con Ubuntu. Cada job corre en un contenedor limpio.

---

### LÃ­neas 38-39: Checkout del CÃ³digo
```yaml
- name: Checkout code
  uses: actions/checkout@v4
```

**ğŸ Simple**: Es como descargar tu proyecto desde GitHub a la computadora que va a trabajar.

**ğŸ”§ TÃ©cnico**: La acciÃ³n `checkout@v4` clona el repositorio en el runner, permitiendo que los pasos siguientes accedan al cÃ³digo.

---

### LÃ­neas 41-49: Verificar package-lock.json
```yaml
- name: Verify package-lock.json exists
  run: |
    if [ ! -f package-lock.json ]; then
      echo "âŒ Error: package-lock.json not found!"
      ls -la
      exit 1
    fi
    echo "âœ… package-lock.json found"
    ls -lh package-lock.json
```

**ğŸ Simple**: Verifica que existe el archivo `package-lock.json` (como verificar que tienes la lista de ingredientes antes de cocinar).

**ğŸ”§ TÃ©cnico**: 
- `if [ ! -f package-lock.json ]`: CondiciÃ³n bash que verifica si el archivo NO existe
- `exit 1`: Falla el step si no encuentra el archivo
- `ls -lh`: Muestra informaciÃ³n del archivo (tamaÃ±o, permisos)

---

### LÃ­neas 51-56: Setup Node.js
```yaml
- name: Setup Node.js
  uses: actions/setup-node@v4
  with:
    node-version: ${{ env.NODE_VERSION }}
    cache: 'npm'
    cache-dependency-path: package-lock.json
```

**ğŸ Simple**: Instala Node.js versiÃ³n 20 y configura un "cajÃ³n" (cache) para guardar las dependencias instaladas, asÃ­ no tiene que descargarlas cada vez.

**ğŸ”§ TÃ©cnico**:
- `setup-node@v4`: AcciÃ³n oficial de GitHub para instalar Node.js
- `cache: 'npm'`: Habilita cache de npm para acelerar instalaciones
- `cache-dependency-path`: Especifica quÃ© archivo usar para invalidar el cache (si cambia package-lock.json, se regenera el cache)

---

### LÃ­neas 58-59: Instalar Dependencias
```yaml
- name: Install dependencies
  run: npm ci
```

**ğŸ Simple**: Instala todas las librerÃ­as que tu proyecto necesita (como instalar todas las herramientas antes de empezar a trabajar).

**ğŸ”§ TÃ©cnico**: `npm ci` (clean install) instala dependencias exactas segÃºn `package-lock.json`. Es mÃ¡s rÃ¡pido y determinÃ­stico que `npm install`.

---

### LÃ­neas 61-62: Linter
```yaml
- name: Run linter
  run: npm run lint || echo "Linting completed"
```

**ğŸ Simple**: Revisa que el cÃ³digo estÃ© bien escrito (como un corrector ortogrÃ¡fico para cÃ³digo).

**ğŸ”§ TÃ©cnico**: Ejecuta el linter (ESLint). El `|| echo` hace que no falle el workflow si hay errores de linting (solo muestra el mensaje).

---

### LÃ­neas 64-65: Tests
```yaml
- name: Run tests
  run: npm test
```

**ğŸ Simple**: Ejecuta todos los tests para verificar que todo funciona (como hacer una prueba antes de entregar un trabajo).

**ğŸ”§ TÃ©cnico**: Ejecuta Jest con cobertura. Si algÃºn test falla, el workflow se detiene.

---

### LÃ­neas 67-68: Build TypeScript
```yaml
- name: Build TypeScript
  run: npm run build
```

**ğŸ Simple**: Convierte el cÃ³digo TypeScript a JavaScript (como compilar un libro antes de publicarlo).

**ğŸ”§ TÃ©cnico**: Ejecuta `tsc` para compilar TypeScript a JavaScript en la carpeta `dist/`. TambiÃ©n copia `database-schema.sql` a `dist/docs/`.

---

### LÃ­neas 70-75: Subir Artifacts
```yaml
- name: Upload build artifacts
  uses: actions/upload-artifact@v4
  with:
    name: dist
    path: dist/
    retention-days: 7
```

**ğŸ Simple**: Guarda la carpeta `dist/` (cÃ³digo compilado) en un "almacÃ©n" para que otros jobs puedan usarla (como guardar algo en un locker compartido).

**ğŸ”§ TÃ©cnico**: Sube la carpeta `dist/` como artifact de GitHub Actions. Otros jobs pueden descargarla con `download-artifact`. Se elimina despuÃ©s de 7 dÃ­as.

---

### LÃ­neas 77-83: Subir Coverage
```yaml
- name: Upload coverage
  uses: codecov/codecov-action@v3
  with:
    files: ./coverage/lcov.info
    flags: unittests
    name: codecov-umbrella
    fail_ci_if_error: false
```

**ğŸ Simple**: Sube el reporte de cobertura de tests a Codecov (como subir las calificaciones de un examen a un sistema de notas).

**ğŸ”§ TÃ©cnico**: Sube el reporte LCOV a Codecov para visualizar cobertura de cÃ³digo. `fail_ci_if_error: false` evita que falle el workflow si Codecov no estÃ¡ disponible.

---

## 3. Job: Deploy Terraform (LÃ­neas 88-915)

### LÃ­neas 88-94: ConfiguraciÃ³n del Job
```yaml
deploy-terraform:
  name: Deploy Infrastructure (Terraform)
  needs: test-and-build
  runs-on: ubuntu-latest
  environment: 
    name: ${{ github.ref == 'refs/heads/main' && 'prod' || github.ref == 'refs/heads/develop' && 'staging' || 'dev' }}
```

**ğŸ Simple**: Este job crea la infraestructura (VPC, RDS, etc.). Solo se ejecuta despuÃ©s de que `test-and-build` termine. El ambiente se elige automÃ¡ticamente segÃºn la rama.

**ğŸ”§ TÃ©cnico**:
- `needs: test-and-build`: Dependencia - este job espera a que el anterior termine
- `environment`: Usa GitHub Environments (dev/staging/prod) que pueden tener secrets especÃ­ficos
- La expresiÃ³n ternaria determina el ambiente segÃºn la rama Git

---

### LÃ­neas 95-111: Outputs del Job
```yaml
outputs:
  vpc_id: ${{ steps.tf-outputs.outputs.vpc_id }}
  private_subnet_ids: ${{ steps.tf-outputs.outputs.private_subnet_ids }}
  # ... mÃ¡s outputs
```

**ğŸ Simple**: Son como "resultados" que este job produce y que otros jobs pueden usar (como pasar una nota con informaciÃ³n al siguiente trabajador).

**ğŸ”§ TÃ©cnico**: Outputs de Terraform que se pasan al job `deploy-sam` como inputs. Permiten compartir informaciÃ³n entre jobs.

---

### LÃ­neas 117-125: Instalar jq
```yaml
- name: Install jq (if needed)
  run: |
    if ! command -v jq >/dev/null 2>&1; then
      echo "ğŸ“¦ Instalando jq..."
      sudo apt-get update && sudo apt-get install -y jq
    else
      echo "âœ… jq ya estÃ¡ instalado"
    fi
    jq --version
```

**ğŸ Simple**: Instala `jq` (herramienta para leer JSON) solo si no estÃ¡ instalado (como verificar si tienes un martillo antes de comprarlo).

**ğŸ”§ TÃ©cnico**: `jq` es necesario para parsear outputs de Terraform (que vienen en JSON). El check evita reinstalarlo innecesariamente.

---

### LÃ­neas 127-131: Setup Terraform
```yaml
- name: Setup Terraform
  uses: hashicorp/setup-terraform@v3
  with:
    terraform_version: ${{ env.TERRAFORM_VERSION }}
    terraform_wrapper: false
```

**ğŸ Simple**: Instala Terraform versiÃ³n 1.6.0 (como instalar una herramienta especÃ­fica para construir).

**ğŸ”§ TÃ©cnico**: Instala Terraform en el PATH del runner. `terraform_wrapper: false` desactiva el wrapper que aÃ±ade logging automÃ¡tico.

---

### LÃ­neas 133-138: Configurar AWS Credentials
```yaml
- name: Configure AWS credentials
  uses: aws-actions/configure-aws-credentials@v4
  with:
    aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
    aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
    aws-region: ${{ env.AWS_REGION }}
```

**ğŸ Simple**: Configura las "credenciales" (usuario y contraseÃ±a) para poder trabajar con AWS (como iniciar sesiÃ³n en una cuenta).

**ğŸ”§ TÃ©cnico**: Configura variables de entorno `AWS_ACCESS_KEY_ID` y `AWS_SECRET_ACCESS_KEY` para que AWS CLI funcione. Los secrets vienen de GitHub Secrets.

---

### LÃ­neas 140-149: Determinar Ambiente
```yaml
- name: Determine environment
  id: determine-env
  run: |
    if [[ "${{ github.ref }}" == "refs/heads/main" ]]; then
      echo "environment=prod" >> $GITHUB_OUTPUT
    elif [[ "${{ github.ref }}" == "refs/heads/develop" ]]; then
      echo "environment=staging" >> $GITHUB_OUTPUT
    else
      echo "environment=dev" >> $GITHUB_OUTPUT
    fi
```

**ğŸ Simple**: Decide quÃ© ambiente usar segÃºn la rama (main = producciÃ³n, develop = staging, otras = dev).

**ğŸ”§ TÃ©cnico**: Usa `github.ref` (referencia Git) para determinar el ambiente. Guarda el resultado en `$GITHUB_OUTPUT` para usarlo en pasos siguientes.

---

### LÃ­neas 151-153: Terraform Init
```yaml
- name: Terraform Init
  working-directory: ./terraform
  run: terraform init
```

**ğŸ Simple**: Inicializa Terraform (como preparar las herramientas antes de empezar a construir).

**ğŸ”§ TÃ©cnico**: `terraform init` descarga providers (plugins) necesarios y configura el backend (donde se guarda el estado).

---

### LÃ­neas 163-377: Limpiar VPCs Duplicadas
```yaml
- name: Cleanup Duplicate VPCs
  if: github.event_name == 'push' || github.event_name == 'workflow_dispatch'
  continue-on-error: true
  run: |
    # ... cÃ³digo largo de limpieza
```

**ğŸ Simple**: Busca y elimina VPCs viejas o duplicadas para no llenar el lÃ­mite de AWS (como limpiar el garaje antes de traer cosas nuevas).

**ğŸ”§ TÃ©cnico**:
- `if`: Solo se ejecuta en push o ejecuciÃ³n manual (no en PRs)
- `continue-on-error: true`: No falla el workflow si hay errores
- El script busca VPCs con el mismo nombre, verifica si tienen RDS, y elimina las duplicadas (manteniendo la mÃ¡s reciente)

**LÃ³gica clave**:
1. Busca VPCs con nombre `agendamiento-v2-{env}-vpc`
2. Si hay mÃ¡s de una, elimina las viejas (excepto la mÃ¡s reciente)
3. Verifica lÃ­mite de VPCs (5 por cuenta AWS)
4. Si estÃ¡ al lÃ­mite, elimina VPCs de proyectos anteriores (`agendamiento-citas-*`)
5. Limpia Elastic IPs no utilizados

---

### LÃ­neas 379-799: Importar Recursos Existentes
```yaml
- name: Import Existing Resources (if any)
  if: github.event_name == 'push' || github.event_name == 'workflow_dispatch'
  working-directory: ./terraform
  continue-on-error: true
  env:
    TF_VAR_environment: ${{ steps.determine-env.outputs.environment }}
    TF_VAR_rds_pe_master_username: ${{ secrets.RDS_PE_USERNAME }}
    # ... mÃ¡s variables
  run: |
    # ... cÃ³digo de importaciÃ³n
```

**ğŸ Simple**: Si ya existen recursos en AWS (de un deploy anterior), los "importa" al estado de Terraform (como registrar cosas que ya tienes en tu inventario).

**ğŸ”§ TÃ©cnico**: 
- `terraform import` trae recursos existentes en AWS al estado de Terraform
- Evita errores de "recurso ya existe"
- Importa: VPC, Subnets, Security Groups, Route Tables, NAT Gateways, RDS, DynamoDB, EventBridge, Secrets Manager

**Recursos importados**:
- `aws_vpc.main`: VPC principal
- `aws_subnet.public[0/1]`, `aws_subnet.private[0/1]`, `aws_subnet.database[0/1]`: Subnets
- `aws_security_group.lambda`, `aws_security_group.rds`: Security Groups
- `aws_route_table.*`: Route Tables y sus asociaciones
- `aws_nat_gateway.main[0/1]`: NAT Gateways
- `aws_db_instance.peru`, `aws_db_instance.chile`: Instancias RDS
- `aws_dynamodb_table.appointments`: Tabla DynamoDB
- `aws_cloudwatch_event_bus.main`: EventBridge Bus
- `aws_secretsmanager_secret.rds_peru`, `aws_secretsmanager_secret.rds_chile`: Secrets

---

### LÃ­neas 801-812: Terraform Plan
```yaml
- name: Terraform Plan (after import)
  if: github.event_name == 'push' || github.event_name == 'workflow_dispatch'
  working-directory: ./terraform
  run: |
    terraform plan \
      -var="environment=${{ steps.determine-env.outputs.environment }}" \
      -var="rds_pe_master_username=${{ secrets.RDS_PE_USERNAME }}" \
      # ... mÃ¡s variables
      -out=tfplan
```

**ğŸ Simple**: Crea un "plan" de lo que Terraform va a hacer (crear, modificar, eliminar) sin hacerlo todavÃ­a (como hacer una lista de compras antes de ir al supermercado).

**ğŸ”§ TÃ©cnico**:
- `terraform plan` compara el estado actual con el cÃ³digo y genera un plan de cambios
- `-out=tfplan`: Guarda el plan en un archivo para aplicarlo despuÃ©s
- Las variables `-var` pasan valores necesarios (como credenciales de RDS)

---

### LÃ­neas 814-871: Esperar RDS Disponible
```yaml
- name: Wait for RDS Instances to be Available
  if: github.event_name == 'push' || github.event_name == 'workflow_dispatch'
  run: |
    # ... cÃ³digo de espera
```

**ğŸ Simple**: Espera a que las bases de datos RDS estÃ©n listas antes de continuar (como esperar a que el horno se caliente antes de meter el pastel).

**ğŸ”§ TÃ©cnico**: 
- Verifica el estado de las instancias RDS (`available`, `modifying`, etc.)
- Espera hasta 30 intentos (15 minutos) con sleep de 30 segundos
- Si estÃ¡ en `modifying` o `backing-up`, espera mÃ¡s tiempo
- Evita errores de `InvalidDBInstanceState` en Terraform

---

### LÃ­neas 873-878: Terraform Apply
```yaml
- name: Terraform Apply
  if: github.event_name == 'push' || github.event_name == 'workflow_dispatch'
  working-directory: ./terraform
  run: |
    terraform apply -auto-approve tfplan
```

**ğŸ Simple**: Aplica el plan creado anteriormente (como ejecutar la lista de compras y comprar todo).

**ğŸ”§ TÃ©cnico**: 
- `terraform apply -auto-approve`: Aplica el plan sin pedir confirmaciÃ³n (necesario en CI/CD)
- `tfplan`: Usa el plan guardado anteriormente (asegura que se aplica exactamente lo planeado)

---

### LÃ­neas 880-914: Obtener Outputs de Terraform
```yaml
- name: Get Terraform Outputs
  id: tf-outputs
  if: github.event_name == 'push' || github.event_name == 'workflow_dispatch'
  working-directory: ./terraform
  run: |
    # Verificar que el state tiene outputs
    if ! terraform output vpc_id > /dev/null 2>&1; then
      echo "âŒ Error: Terraform outputs no estÃ¡n disponibles"
      exit 1
    fi
    
    # Obtener outputs
    echo "vpc_id=$(terraform output -raw vpc_id)" >> $GITHUB_OUTPUT
    PRIVATE_SUBNETS=$(terraform output -json private_subnet_ids | jq -r 'join(",")')
    echo "private_subnet_ids=$PRIVATE_SUBNETS" >> $GITHUB_OUTPUT
    # ... mÃ¡s outputs
```

**ğŸ Simple**: Obtiene informaciÃ³n importante creada por Terraform (como IDs de VPC, subnets, etc.) y la guarda para que otros jobs la usen.

**ğŸ”§ TÃ©cnico**:
- `terraform output`: Obtiene valores de salida definidos en `outputs.tf`
- `-raw`: Obtiene el valor sin formato JSON
- `-json` + `jq`: Para listas, convierte JSON a string separado por comas
- `>> $GITHUB_OUTPUT`: Guarda en outputs del step para usar en otros jobs

**Outputs obtenidos**:
- `vpc_id`: ID de la VPC
- `private_subnet_ids`: IDs de subnets privadas (lista â†’ string separado por comas)
- `lambda_sg_id`: ID del Security Group para Lambda
- `dynamodb_table`, `dynamodb_table_arn`: Nombre y ARN de DynamoDB
- `sns_peru_arn`, `sns_chile_arn`: ARNs de topics SNS
- `sqs_queue_url_peru`, `sqs_queue_url_chile`: URLs de colas SQS
- `sqs_queue_arn_peru`, `sqs_queue_arn_chile`: ARNs de colas SQS
- `sqs_completion_queue_url`, `sqs_completion_queue_arn`: Cola de completaciÃ³n
- `eventbridge_bus_name`: Nombre del bus EventBridge
- `rds_peru_secret_arn`, `rds_chile_secret_arn`: ARNs de secrets de RDS

---

## 4. Job: Deploy SAM (LÃ­neas 919-1295)

### LÃ­neas 919-925: ConfiguraciÃ³n del Job
```yaml
deploy-sam:
  name: Deploy Lambda Functions (SAM)
  needs: [test-and-build, deploy-terraform]
  runs-on: ubuntu-latest
  if: github.event_name == 'push' || github.event_name == 'workflow_dispatch'
  environment: 
    name: ${{ github.ref == 'refs/heads/main' && 'prod' || github.ref == 'refs/heads/develop' && 'staging' || 'dev' }}
```

**ğŸ Simple**: Este job despliega las funciones Lambda y API Gateway. Espera a que los tests pasen Y que la infraestructura estÃ© lista.

**ğŸ”§ TÃ©cnico**:
- `needs: [test-and-build, deploy-terraform]`: Espera a que AMBOS jobs terminen
- `if`: Solo se ejecuta en push o ejecuciÃ³n manual (no en PRs)

---

### LÃ­neas 941-945: Descargar Artifacts
```yaml
- name: Download build artifacts
  uses: actions/download-artifact@v4
  with:
    name: dist
    path: dist/
```

**ğŸ Simple**: Descarga el cÃ³digo compilado que el job `test-and-build` guardÃ³ (como recibir un paquete que alguien te enviÃ³).

**ğŸ”§ TÃ©cnico**: Descarga el artifact `dist` (cÃ³digo TypeScript compilado) para empaquetarlo en las funciones Lambda.

---

### LÃ­neas 947-950: Setup AWS SAM
```yaml
- name: Setup AWS SAM
  uses: aws-actions/setup-sam@v2
  with:
    use-installer: true
```

**ğŸ Simple**: Instala AWS SAM CLI (herramienta para desplegar funciones Lambda).

**ğŸ”§ TÃ©cnico**: Instala SAM CLI en el PATH del runner para poder ejecutar `sam build` y `sam deploy`.

---

### LÃ­neas 974-1010: Validar ParÃ¡metros SAM
```yaml
- name: Validate SAM Parameters
  run: |
    echo "ğŸ” Validando parÃ¡metros para SAM Deploy..."
    
    VPC_ID="${{ needs.deploy-terraform.outputs.vpc_id }}"
    SUBNETS="${{ needs.deploy-terraform.outputs.private_subnet_ids }}"
    SG_ID="${{ needs.deploy-terraform.outputs.lambda_sg_id }}"
    
    # Verificar VPC
    if ! aws ec2 describe-vpcs --vpc-ids "$VPC_ID" --region ${{ env.AWS_REGION }} >/dev/null 2>&1; then
      echo "âŒ VPC $VPC_ID no existe"
      exit 1
    fi
    echo "âœ… VPC existe"
    
    # Verificar Security Group
    # Verificar Subnets
```

**ğŸ Simple**: Verifica que todos los recursos de red (VPC, Security Groups, Subnets) existan antes de desplegar Lambda (como verificar que tienes todos los materiales antes de construir).

**ğŸ”§ TÃ©cnico**: 
- Usa `aws ec2 describe-*` para verificar que los recursos existen
- Si alguno no existe, falla el workflow antes de intentar el deploy
- Evita errores costosos en tiempo de ejecuciÃ³n

---

### LÃ­neas 1012-1184: Verificar y Arreglar Estado de CloudFormation
```yaml
- name: Check and Fix CloudFormation Stack State
  continue-on-error: false
  run: |
    STACK_NAME="agendamiento-citas-${{ steps.determine-env.outputs.environment }}"
    # ... cÃ³digo largo
```

**ğŸ Simple**: Verifica el estado del stack de CloudFormation. Si estÃ¡ en un estado fallido (como `ROLLBACK_COMPLETE`), lo elimina para poder crear uno nuevo (como limpiar un intento fallido antes de intentar de nuevo).

**ğŸ”§ TÃ©cnico**:
- CloudFormation stacks pueden quedar en estados fallidos (`ROLLBACK_COMPLETE`, `CREATE_FAILED`, etc.)
- Estos estados bloquean nuevos deploys
- El script:
  1. Verifica el estado del stack
  2. Si estÃ¡ en `DELETE_IN_PROGRESS`, espera hasta 5 minutos adicionales
  3. Si estÃ¡ en estado fallido, lo elimina
  4. Espera hasta 20 minutos para que se elimine (Lambda en VPC tarda mucho)
  5. Si alcanza timeout pero estÃ¡ en `DELETE_IN_PROGRESS`, continÃºa (no falla)

**Estados manejados**:
- `ROLLBACK_IN_PROGRESS`, `ROLLBACK_COMPLETE`, `ROLLBACK_FAILED`
- `DELETE_FAILED`, `CREATE_FAILED`
- `UPDATE_ROLLBACK_IN_PROGRESS`, `UPDATE_ROLLBACK_COMPLETE`, `UPDATE_ROLLBACK_FAILED`

---

### LÃ­neas 1186-1241: SAM Deploy
```yaml
- name: SAM Deploy
  working-directory: ./sam
  timeout-minutes: 30
  run: |
    echo "ğŸš€ Iniciando SAM Deploy..."
    
    set +e  # No salir inmediatamente en error
    sam deploy \
      --stack-name agendamiento-citas-${{ steps.determine-env.outputs.environment }} \
      --resolve-s3 \
      --parameter-overrides \
        Environment=${{ steps.determine-env.outputs.environment }} \
        VpcId=${{ needs.deploy-terraform.outputs.vpc_id }} \
        # ... mÃ¡s parÃ¡metros
      --capabilities CAPABILITY_IAM \
      --no-confirm-changeset \
      --no-fail-on-empty-changeset \
      --disable-rollback \
      --debug
    
    SAM_EXIT_CODE=$?
    set -e  # Reactivar salir en error
    
    if [ $SAM_EXIT_CODE -ne 0 ]; then
      # Mostrar errores
      exit 1
    fi
```

**ğŸ Simple**: Despliega las funciones Lambda y API Gateway usando SAM. Pasa todos los parÃ¡metros necesarios (VPC, subnets, etc.) que vienen de Terraform.

**ğŸ”§ TÃ©cnico**:
- `sam deploy`: Despliega el stack de CloudFormation definido en `sam/template.yaml`
- `--resolve-s3`: Crea automÃ¡ticamente un bucket S3 para guardar el cÃ³digo de Lambda
- `--parameter-overrides`: Pasa parÃ¡metros al template SAM (vienen de outputs de Terraform)
- `--capabilities CAPABILITY_IAM`: Permite crear roles IAM (requerido por CloudFormation)
- `--no-confirm-changeset`: No pide confirmaciÃ³n (automÃ¡tico en CI/CD)
- `--no-fail-on-empty-changeset`: No falla si no hay cambios
- `--disable-rollback`: No elimina el stack si falla (permite debugging)
- `--debug`: Muestra logs detallados
- `set +e` / `set -e`: Manejo de errores - captura el cÃ³digo de salida antes de verificar

**ParÃ¡metros pasados**:
- `Environment`: dev/staging/prod
- `VpcId`: ID de la VPC
- `PrivateSubnetIds`: IDs de subnets privadas (comma-separated)
- `LambdaSecurityGroupId`: ID del Security Group
- `DynamoDBTableName`, `DynamoDBTableArn`: Info de DynamoDB
- `SNSTopicArnPeru`, `SNSTopicArnChile`: ARNs de SNS
- `SQSQueueUrlPeru`, `SQSQueueUrlChile`: URLs de SQS
- `SQSQueueArnPeru`, `SQSQueueArnChile`: ARNs de SQS
- `SQSCompletionQueueUrl`, `SQSCompletionQueueArn`: Cola de completaciÃ³n
- `EventBridgeBusName`: Nombre del bus
- `RDSPeruSecretArn`, `RDSChileSecretArn`: ARNs de secrets de RDS

---

### LÃ­neas 1243-1271: Obtener API URL
```yaml
- name: Get API URL
  id: sam-deploy
  run: |
    STACK_NAME="agendamiento-citas-${{ steps.determine-env.outputs.environment }}"
    
    echo "ğŸ” Obteniendo API URL del stack: $STACK_NAME"
    
    # Esperar a que el stack estÃ© completamente actualizado
    sleep 10
    
    # Get API URL
    API_URL=$(aws cloudformation describe-stacks \
      --stack-name "$STACK_NAME" \
      --region ${{ env.AWS_REGION }} \
      --query 'Stacks[0].Outputs[?OutputKey==`ApiUrl`].OutputValue' \
      --output text)
    
    if [ -z "$API_URL" ] || [ "$API_URL" == "None" ]; then
      echo "âŒ No se pudo obtener API URL"
      exit 1
    fi
    
    echo "âœ… API URL obtenida: $API_URL"
    echo "api_url=$API_URL" >> $GITHUB_OUTPUT
```

**ğŸ Simple**: Obtiene la URL del API Gateway que se acaba de crear (como obtener la direcciÃ³n de una tienda que acabas de abrir).

**ğŸ”§ TÃ©cnico**:
- `sleep 10`: Espera a que CloudFormation termine de crear el stack
- `aws cloudformation describe-stacks`: Obtiene informaciÃ³n del stack
- `--query`: Filtra el output `ApiUrl` del stack
- Guarda la URL en `$GITHUB_OUTPUT` para usarla en otros jobs

---

### LÃ­neas 1273-1288: Mostrar Eventos en Caso de Falla
```yaml
- name: Show CloudFormation Events on Failure
  if: failure()
  run: |
    # Obtener los Ãºltimos 20 eventos del stack
    aws cloudformation describe-stack-events \
      --stack-name "$STACK_NAME" \
      --max-items 20 \
      --query 'StackEvents[].[Timestamp,LogicalResourceId,ResourceType,ResourceStatus,ResourceStatusReason]' \
      --output table
```

**ğŸ Simple**: Si algo falla, muestra los Ãºltimos eventos de CloudFormation para ayudar a entender quÃ© saliÃ³ mal (como mostrar el registro de errores cuando algo falla).

**ğŸ”§ TÃ©cnico**: 
- `if: failure()`: Solo se ejecuta si algÃºn step anterior fallÃ³
- Muestra eventos de CloudFormation en formato tabla para debugging

---

## 5. Job: Init Databases (LÃ­neas 1299-1339)

### LÃ­neas 1299-1307: ConfiguraciÃ³n (Deshabilitado)
```yaml
init-databases:
  name: Initialize RDS Databases
  needs: [deploy-terraform]
  runs-on: ubuntu-latest
  if: false  # Deshabilitado: La inicializaciÃ³n de DB se harÃ¡ manualmente
  continue-on-error: true
```

**ğŸ Simple**: Este job estÃ¡ deshabilitado. La inicializaciÃ³n de bases de datos se hace manualmente usando el workflow "Database Migrations".

**ğŸ”§ TÃ©cnico**: 
- `if: false`: El job nunca se ejecuta
- EstÃ¡ comentado porque RDS estÃ¡ en subnets privadas y GitHub Actions no puede conectarse directamente
- Se usa una Lambda function para ejecutar las migraciones (workflow separado)

---

## 6. Job: Integration Tests (LÃ­neas 1344-1389)

### LÃ­neas 1344-1351: ConfiguraciÃ³n (Deshabilitado)
```yaml
integration-tests:
  name: Integration Tests
  needs: [deploy-sam]
  runs-on: ubuntu-latest
  if: false  # Deshabilitado temporalmente - Implementar tests reales
  continue-on-error: true
```

**ğŸ Simple**: Este job tambiÃ©n estÃ¡ deshabilitado. Los tests de integraciÃ³n se implementarÃ¡n cuando la base de datos estÃ© lista.

**ğŸ”§ TÃ©cnico**: 
- `if: false`: No se ejecuta
- EstÃ¡ deshabilitado porque requiere:
  1. Base de datos inicializada
  2. Tests reales implementados (no solo curl bÃ¡sico)

---

## 7. Job: Notify (LÃ­neas 1394-1418)

### LÃ­neas 1394-1398: ConfiguraciÃ³n
```yaml
notify:
  name: Send Notification
  needs: [deploy-sam]
  runs-on: ubuntu-latest
  if: always() && (github.event_name == 'push' || github.event_name == 'workflow_dispatch')
```

**ğŸ Simple**: Este job siempre se ejecuta (incluso si algo fallÃ³) y muestra un resumen del deploy.

**ğŸ”§ TÃ©cnico**:
- `if: always()`: Se ejecuta sin importar si los jobs anteriores fallaron
- `needs: [deploy-sam]`: Espera a que el deploy de SAM termine (exitoso o fallido)

---

### LÃ­neas 1401-1411: NotificaciÃ³n de Ã‰xito
```yaml
- name: Send success notification
  if: needs.deploy-sam.result == 'success'
  run: |
    echo "âœ… Deployment successful!"
    echo "ğŸš€ API URL: ${{ needs.deploy-sam.outputs.api_url }}"
    echo "ğŸŒ Environment: ${{ github.ref }}"
    echo ""
    echo "ğŸ“ PrÃ³ximos pasos:"
    echo "   1. Ejecutar workflow 'Database Migrations' para inicializar DBs"
    echo "   2. Probar endpoints de la API"
    echo "   3. Habilitar integration tests cuando DB estÃ© lista"
```

**ğŸ Simple**: Si el deploy fue exitoso, muestra un mensaje con la URL del API y los prÃ³ximos pasos.

**ğŸ”§ TÃ©cnico**: 
- `if: needs.deploy-sam.result == 'success'`: Solo se ejecuta si el deploy fue exitoso
- Muestra informaciÃ³n Ãºtil: API URL, ambiente, prÃ³ximos pasos

---

### LÃ­neas 1413-1417: NotificaciÃ³n de Falla
```yaml
- name: Send failure notification
  if: needs.deploy-sam.result != 'success'
  run: |
    echo "âŒ Deployment failed!"
    echo "ğŸ” Check the logs for details"
```

**ğŸ Simple**: Si el deploy fallÃ³, muestra un mensaje indicando que hay que revisar los logs.

**ğŸ”§ TÃ©cnico**: Mensaje simple de error. Los detalles estÃ¡n en los logs de los jobs anteriores.

---

## ğŸ¯ Resumen del Flujo Completo

### Flujo Visual:
```
1. Push a main/develop
   â†“
2. test-and-build
   - Instala dependencias
   - Ejecuta tests
   - Compila TypeScript
   - Guarda artifacts
   â†“
3. deploy-terraform (espera a test-and-build)
   - Limpia VPCs viejas
   - Importa recursos existentes
   - Crea/actualiza infraestructura (VPC, RDS, DynamoDB, etc.)
   - Guarda outputs (VPC ID, Subnets, etc.)
   â†“
4. deploy-sam (espera a test-and-build Y deploy-terraform)
   - Descarga cÃ³digo compilado
   - Valida parÃ¡metros
   - Verifica/limpia stack de CloudFormation
   - Despliega Lambda functions y API Gateway
   - Obtiene API URL
   â†“
5. notify (siempre se ejecuta)
   - Muestra resultado (Ã©xito o fallo)
   - Muestra prÃ³ximos pasos
```

### Jobs Deshabilitados:
- `init-databases`: Se hace manualmente con workflow "Database Migrations"
- `integration-tests`: Se implementarÃ¡ cuando DB estÃ© lista

---

## ğŸ”‘ Conceptos Clave

### 1. **Dependencias entre Jobs** (`needs`)
- `deploy-terraform` necesita `test-and-build`
- `deploy-sam` necesita `test-and-build` Y `deploy-terraform`
- Esto asegura que todo se ejecute en el orden correcto

### 2. **Compartir InformaciÃ³n entre Jobs** (`outputs`)
- Terraform crea recursos y guarda IDs en `outputs`
- SAM recibe esos outputs como `parameter-overrides`
- Permite que los jobs se comuniquen

### 3. **Manejo de Errores**
- `continue-on-error: true`: No falla el workflow si este step falla
- `if: failure()`: Se ejecuta solo si algo fallÃ³
- `set +e` / `set -e`: Controla si el script se detiene en errores

### 4. **Idempotencia**
- Terraform importa recursos existentes antes de crear nuevos
- Evita errores de "recurso ya existe"
- Permite re-ejecutar el workflow sin problemas

### 5. **Ambientes**
- Se determina automÃ¡ticamente segÃºn la rama
- `main` â†’ `prod`
- `develop` â†’ `staging`
- Otras â†’ `dev`

---

## ğŸ“š Recursos Adicionales

- **GitHub Actions**: https://docs.github.com/en/actions
- **Terraform**: https://www.terraform.io/docs
- **AWS SAM**: https://docs.aws.amazon.com/serverless-application-model/
- **CloudFormation**: https://docs.aws.amazon.com/cloudformation/

---

Â¿Tienes preguntas sobre alguna secciÃ³n especÃ­fica? ğŸ¤”

