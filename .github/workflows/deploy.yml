name: Deploy Infrastructure and Application

on:
  push:
    branches:
      - main
      - develop
  pull_request:
    branches:
      - main
      - develop
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment to deploy'
        required: true
        default: 'dev'
        type: choice
        options:
          - dev
          - staging
          - prod

env:
  AWS_REGION: us-east-1
  NODE_VERSION: '20'
  TERRAFORM_VERSION: '1.6.0'

jobs:
  # ===============================================
  # Test y Build
  # ===============================================
  test-and-build:
    name: Test and Build
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Verify package-lock.json exists
        run: |
          if [ ! -f package-lock.json ]; then
            echo "‚ùå Error: package-lock.json not found!"
            ls -la
            exit 1
          fi
          echo "‚úÖ package-lock.json found"
          ls -lh package-lock.json

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: package-lock.json

      - name: Install dependencies
        run: npm ci

      - name: Run linter
        run: npm run lint || echo "Linting completed"

      - name: Run tests
        run: npm test

      - name: Build TypeScript
        run: npm run build

      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: dist
          path: dist/
          retention-days: 7

      - name: Upload coverage
        uses: codecov/codecov-action@v3
        with:
          files: ./coverage/lcov.info
          flags: unittests
          name: codecov-umbrella
          fail_ci_if_error: false

  # ===============================================
  # Deploy Infrastructure (Terraform)
  # ===============================================
  deploy-terraform:
    name: Deploy Infrastructure (Terraform)
    needs: test-and-build
    runs-on: ubuntu-latest
    environment: 
      name: ${{ github.ref == 'refs/heads/main' && 'prod' || github.ref == 'refs/heads/develop' && 'staging' || 'dev' }}
    
    outputs:
      vpc_id: ${{ steps.tf-outputs.outputs.vpc_id }}
      private_subnet_ids: ${{ steps.tf-outputs.outputs.private_subnet_ids }}
      lambda_sg_id: ${{ steps.tf-outputs.outputs.lambda_sg_id }}
      dynamodb_table: ${{ steps.tf-outputs.outputs.dynamodb_table }}
      dynamodb_table_arn: ${{ steps.tf-outputs.outputs.dynamodb_table_arn }}
      sns_peru_arn: ${{ steps.tf-outputs.outputs.sns_peru_arn }}
      sns_chile_arn: ${{ steps.tf-outputs.outputs.sns_chile_arn }}
      sqs_queue_url_peru: ${{ steps.tf-outputs.outputs.sqs_queue_url_peru }}
      sqs_queue_url_chile: ${{ steps.tf-outputs.outputs.sqs_queue_url_chile }}
      sqs_queue_arn_peru: ${{ steps.tf-outputs.outputs.sqs_queue_arn_peru }}
      sqs_queue_arn_chile: ${{ steps.tf-outputs.outputs.sqs_queue_arn_chile }}
      sqs_completion_queue_url: ${{ steps.tf-outputs.outputs.sqs_completion_queue_url }}
      sqs_completion_queue_arn: ${{ steps.tf-outputs.outputs.sqs_completion_queue_arn }}
      eventbridge_bus_name: ${{ steps.tf-outputs.outputs.eventbridge_bus_name }}
      rds_peru_secret_arn: ${{ steps.tf-outputs.outputs.rds_peru_secret_arn }}
      rds_chile_secret_arn: ${{ steps.tf-outputs.outputs.rds_chile_secret_arn }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TERRAFORM_VERSION }}
          terraform_wrapper: false

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Determine environment
        id: determine-env
        run: |
          if [[ "${{ github.ref }}" == "refs/heads/main" ]]; then
            echo "environment=prod" >> $GITHUB_OUTPUT
          elif [[ "${{ github.ref }}" == "refs/heads/develop" ]]; then
            echo "environment=staging" >> $GITHUB_OUTPUT
          else
            echo "environment=dev" >> $GITHUB_OUTPUT
          fi

      - name: Terraform Init
        working-directory: ./terraform
        run: terraform init

      - name: Terraform Format Check
        working-directory: ./terraform
        run: terraform fmt -check || true

      - name: Terraform Validate
        working-directory: ./terraform
        run: terraform validate

      - name: Cleanup Duplicate VPCs
        if: github.event_name == 'push' || github.event_name == 'workflow_dispatch'
        continue-on-error: true
        run: |
          ENV="${{ steps.determine-env.outputs.environment }}"
          PROJECT_NAME="agendamiento-v2"
          REGION="us-east-1"
          VPC_NAME="${PROJECT_NAME}-${ENV}-vpc"
          
          echo "üßπ Limpiando VPCs duplicadas/viejas..."
          
          # Obtener todas las VPCs con el mismo nombre
          VPC_IDS=$(aws ec2 describe-vpcs \
            --region "$REGION" \
            --filters "Name=tag:Name,Values=$VPC_NAME" \
            --query 'Vpcs[].[VpcId,CreationDate]' \
            --output text | sort -k2 -r)
          
          if [ -z "$VPC_IDS" ]; then
            echo "‚úÖ No hay VPCs duplicadas con nombre: $VPC_NAME"
          else
            echo "üìä VPCs encontradas con nombre $VPC_NAME:"
            echo "$VPC_IDS" | while read VPC_ID CREATION_DATE; do
              echo "  - $VPC_ID (creada: $CREATION_DATE)"
            done
            
            # Contar VPCs
            VPC_COUNT=$(echo "$VPC_IDS" | wc -l | tr -d ' ')
            
            if [ "$VPC_COUNT" -gt 1 ]; then
              echo ""
              echo "üóëÔ∏è  Eliminando VPCs duplicadas (manteniendo la m√°s reciente)..."
              
              # Eliminar todas excepto la primera (m√°s reciente)
              echo "$VPC_IDS" | tail -n +2 | while read VPC_ID CREATION_DATE; do
                echo "  Eliminando VPC duplicada: $VPC_ID"
                
                # Verificar si tiene recursos en uso
                RDS_COUNT=$(aws rds describe-db-instances --region "$REGION" \
                  --query "length(DBInstances[?DBSubnetGroup.VpcId=='$VPC_ID'])" \
                  --output text 2>/dev/null || echo "0")
                
                if [ "$RDS_COUNT" -gt 0 ]; then
                  echo "    ‚ö†Ô∏è  VPC tiene $RDS_COUNT instancias RDS, no se eliminar√°"
                else
                  # Eliminar recursos de la VPC
                  echo "    üóëÔ∏è  Eliminando recursos de VPC $VPC_ID..."
                  
                  # Eliminar NAT Gateways
                  NAT_GWS=$(aws ec2 describe-nat-gateways --region "$REGION" \
                    --filter "Name=vpc-id,Values=$VPC_ID" "Name=state,Values=available,pending" \
                    --query 'NatGateways[].NatGatewayId' --output text 2>/dev/null || echo "")
                  for NAT in $NAT_GWS; do
                    aws ec2 delete-nat-gateway --nat-gateway-id "$NAT" --region "$REGION" >/dev/null 2>&1 && \
                      echo "      ‚úÖ NAT Gateway $NAT elimin√°ndose..." || true
                  done
                  
                  # Desconectar y eliminar Internet Gateways
                  IGW=$(aws ec2 describe-internet-gateways --region "$REGION" \
                    --filters "Name=attachment.vpc-id,Values=$VPC_ID" \
                    --query 'InternetGateways[0].InternetGatewayId' --output text 2>/dev/null || echo "None")
                  if [ "$IGW" != "None" ] && [ ! -z "$IGW" ]; then
                    aws ec2 detach-internet-gateway --internet-gateway-id "$IGW" --vpc-id "$VPC_ID" --region "$REGION" >/dev/null 2>&1 || true
                    aws ec2 delete-internet-gateway --internet-gateway-id "$IGW" --region "$REGION" >/dev/null 2>&1 && \
                      echo "      ‚úÖ Internet Gateway eliminado" || true
                  fi
                  
                  # Eliminar Subnets
                  SUBNETS=$(aws ec2 describe-subnets --region "$REGION" \
                    --filters "Name=vpc-id,Values=$VPC_ID" \
                    --query 'Subnets[].SubnetId' --output text 2>/dev/null || echo "")
                  for SUBNET in $SUBNETS; do
                    aws ec2 delete-subnet --subnet-id "$SUBNET" --region "$REGION" >/dev/null 2>&1 || true
                  done
                  [ ! -z "$SUBNETS" ] && echo "      ‚úÖ Subnets eliminadas" || true
                  
                  # Eliminar Security Groups (excepto default)
                  SGS=$(aws ec2 describe-security-groups --region "$REGION" \
                    --filters "Name=vpc-id,Values=$VPC_ID" \
                    --query 'SecurityGroups[?GroupName!=`default`].GroupId' --output text 2>/dev/null || echo "")
                  for SG in $SGS; do
                    aws ec2 delete-security-group --group-id "$SG" --region "$REGION" >/dev/null 2>&1 || true
                  done
                  [ ! -z "$SGS" ] && echo "      ‚úÖ Security Groups eliminados" || true
                  
                  # Eliminar Route Tables (excepto main)
                  RTS=$(aws ec2 describe-route-tables --region "$REGION" \
                    --filters "Name=vpc-id,Values=$VPC_ID" \
                    --query 'RouteTables[?Associations[0].Main!=`true`].RouteTableId' --output text 2>/dev/null || echo "")
                  for RT in $RTS; do
                    # Desasociar de subnets
                    ASSOCS=$(aws ec2 describe-route-tables --region "$REGION" \
                      --route-table-ids "$RT" \
                      --query 'RouteTables[0].Associations[?SubnetId!=`null`].RouteTableAssociationId' \
                      --output text 2>/dev/null || echo "")
                    for ASSOC in $ASSOCS; do
                      aws ec2 disassociate-route-table --association-id "$ASSOC" --region "$REGION" >/dev/null 2>&1 || true
                    done
                    aws ec2 delete-route-table --route-table-id "$RT" --region "$REGION" >/dev/null 2>&1 || true
                  done
                  [ ! -z "$RTS" ] && echo "      ‚úÖ Route Tables eliminadas" || true
                  
                  # Intentar eliminar VPC
                  sleep 5  # Esperar a que recursos se eliminen
                  if aws ec2 delete-vpc --vpc-id "$VPC_ID" --region "$REGION" 2>&1; then
                    echo "      ‚úÖ VPC $VPC_ID eliminada exitosamente"
                  else
                    echo "      ‚ö†Ô∏è  VPC $VPC_ID a√∫n tiene dependencias (se reintentar√° en pr√≥ximo deploy)"
                  fi
                fi
              done
            else
              echo "‚úÖ Solo hay 1 VPC, no hay duplicadas"
            fi
          fi
          
          # Verificar l√≠mite de VPCs
          TOTAL_VPCS=$(aws ec2 describe-vpcs --region "$REGION" --query 'length(Vpcs)' --output text)
          echo ""
          echo "üìä Total VPCs en cuenta: $TOTAL_VPCS / 5 (l√≠mite)"
          
          if [ "$TOTAL_VPCS" -ge 5 ]; then
            echo "‚ö†Ô∏è  L√≠mite de VPCs alcanzado. Limpiando VPCs viejas de proyectos anteriores..."
            
            # Buscar VPCs viejas de agendamiento-citas (proyecto anterior)
            OLD_VPCS=$(aws ec2 describe-vpcs \
              --region "$REGION" \
              --filters "Name=tag:Name,Values=agendamiento-citas-*-vpc" \
              --query 'Vpcs[].[VpcId,CreationDate]' \
              --output text | sort -k2)
            
            if [ ! -z "$OLD_VPCS" ]; then
              echo "üóëÔ∏è  Eliminando VPCs viejas de agendamiento-citas..."
              echo "$OLD_VPCS" | head -n 1 | while read OLD_VPC_ID CREATION_DATE; do
                echo "  Eliminando VPC vieja: $OLD_VPC_ID"
                
                # Verificar si tiene RDS
                RDS_COUNT=$(aws rds describe-db-instances --region "$REGION" \
                  --query "length(DBInstances[?DBSubnetGroup.VpcId=='$OLD_VPC_ID'])" \
                  --output text 2>/dev/null || echo "0")
                
                if [ "$RDS_COUNT" -gt 0 ]; then
                  echo "    ‚ö†Ô∏è  VPC tiene $RDS_COUNT instancias RDS, no se eliminar√°"
                else
                  # Eliminar recursos (misma l√≥gica que arriba)
                  echo "    üóëÔ∏è  Eliminando recursos..."
                  
                  # NAT Gateways
                  NAT_GWS=$(aws ec2 describe-nat-gateways --region "$REGION" \
                    --filter "Name=vpc-id,Values=$OLD_VPC_ID" "Name=state,Values=available,pending" \
                    --query 'NatGateways[].NatGatewayId' --output text 2>/dev/null || echo "")
                  for NAT in $NAT_GWS; do
                    aws ec2 delete-nat-gateway --nat-gateway-id "$NAT" --region "$REGION" >/dev/null 2>&1 || true
                  done
                  
                  # Internet Gateways
                  IGW=$(aws ec2 describe-internet-gateways --region "$REGION" \
                    --filters "Name=attachment.vpc-id,Values=$OLD_VPC_ID" \
                    --query 'InternetGateways[0].InternetGatewayId' --output text 2>/dev/null || echo "None")
                  if [ "$IGW" != "None" ] && [ ! -z "$IGW" ]; then
                    aws ec2 detach-internet-gateway --internet-gateway-id "$IGW" --vpc-id "$OLD_VPC_ID" --region "$REGION" >/dev/null 2>&1 || true
                    aws ec2 delete-internet-gateway --internet-gateway-id "$IGW" --region "$REGION" >/dev/null 2>&1 || true
                  fi
                  
                  # Subnets, Security Groups, Route Tables (simplificado)
                  aws ec2 describe-subnets --region "$REGION" --filters "Name=vpc-id,Values=$OLD_VPC_ID" \
                    --query 'Subnets[].SubnetId' --output text 2>/dev/null | tr '\t' '\n' | \
                    xargs -I {} aws ec2 delete-subnet --subnet-id {} --region "$REGION" >/dev/null 2>&1 || true
                  
                  aws ec2 describe-security-groups --region "$REGION" \
                    --filters "Name=vpc-id,Values=$OLD_VPC_ID" \
                    --query 'SecurityGroups[?GroupName!=`default`].GroupId' --output text 2>/dev/null | \
                    tr '\t' '\n' | xargs -I {} aws ec2 delete-security-group --group-id {} --region "$REGION" >/dev/null 2>&1 || true
                  
                  # Intentar eliminar VPC
                  sleep 5
                  if aws ec2 delete-vpc --vpc-id "$OLD_VPC_ID" --region "$REGION" 2>&1; then
                    echo "    ‚úÖ VPC $OLD_VPC_ID eliminada"
                  else
                    echo "    ‚ö†Ô∏è  VPC $OLD_VPC_ID a√∫n tiene dependencias"
                  fi
                fi
              done
            fi
          fi
          
          echo "‚úÖ Limpieza de VPCs completada"

      - name: Import Existing Resources (if any)
        if: github.event_name == 'push' || github.event_name == 'workflow_dispatch'
        working-directory: ./terraform
        continue-on-error: true
        env:
          # Pasar variables de RDS como environment variables para terraform import
          TF_VAR_environment: ${{ steps.determine-env.outputs.environment }}
          TF_VAR_rds_pe_master_username: ${{ secrets.RDS_PE_USERNAME }}
          TF_VAR_rds_pe_master_password: ${{ secrets.RDS_PE_PASSWORD }}
          TF_VAR_rds_cl_master_username: ${{ secrets.RDS_CL_USERNAME }}
          TF_VAR_rds_cl_master_password: ${{ secrets.RDS_CL_PASSWORD }}
        run: |
          # Determinar nombre del proyecto basado en environment
          ENV="${{ steps.determine-env.outputs.environment }}"
          PROJECT_NAME="agendamiento-v2"
          REGION="us-east-1"
          
          echo "üîç Verificando recursos existentes que pueden necesitar importaci√≥n..."
          
          # Importar VPC si existe
          VPC_NAME="${PROJECT_NAME}-${ENV}-vpc"
          EXISTING_VPC=$(aws ec2 describe-vpcs \
            --region "$REGION" \
            --filters "Name=tag:Name,Values=$VPC_NAME" \
            --query 'Vpcs[0].VpcId' \
            --output text)
          
          if [ ! -z "$EXISTING_VPC" ] && [ "$EXISTING_VPC" != "None" ]; then
            echo "üì¶ VPC existe: $EXISTING_VPC ($VPC_NAME)"
            if terraform state show aws_vpc.main >/dev/null 2>&1; then
              echo "‚úÖ VPC ya est√° en el estado de Terraform"
            else
              echo "üîÑ Importando VPC al estado de Terraform..."
              terraform import aws_vpc.main "$EXISTING_VPC" 2>&1 || \
                echo "‚ö†Ô∏è  No se pudo importar (continuando...)"
            fi
          else
            echo "‚úÖ VPC no existe, Terraform la crear√°"
          fi
          
          # Importar DB Subnet Group si existe
          DB_SUBNET_GROUP_NAME="${PROJECT_NAME}-${ENV}-db-subnet-group"
          if aws rds describe-db-subnet-groups --db-subnet-group-name "$DB_SUBNET_GROUP_NAME" --region "$REGION" >/dev/null 2>&1; then
            echo "üì¶ DB Subnet Group existe: $DB_SUBNET_GROUP_NAME"
            
            # Verificar si ya est√° en el estado de Terraform
            if terraform state show aws_db_subnet_group.main >/dev/null 2>&1; then
              echo "‚úÖ DB Subnet Group ya est√° en el estado de Terraform"
            else
              echo "üîÑ Importando DB Subnet Group al estado de Terraform..."
              
              # Importar el recurso
              if terraform import aws_db_subnet_group.main "$DB_SUBNET_GROUP_NAME" 2>&1; then
                echo "‚úÖ DB Subnet Group importado exitosamente"
                
                # Verificar que las subnets coinciden (opcional, solo para logging)
                EXISTING_SUBNETS=$(aws rds describe-db-subnet-groups \
                  --db-subnet-group-name "$DB_SUBNET_GROUP_NAME" \
                  --region "$REGION" \
                  --query 'DBSubnetGroups[0].Subnets[].SubnetIdentifier' \
                  --output text | tr '\t' ' ')
                echo "‚ÑπÔ∏è  Subnets en DB Subnet Group existente: $EXISTING_SUBNETS"
                echo "‚ÑπÔ∏è  Terraform verificar√° que las subnets coincidan en el plan"
              else
                echo "‚ö†Ô∏è  No se pudo importar (puede ser por diferencias en configuraci√≥n)"
                echo "‚ÑπÔ∏è  Terraform intentar√° crear uno nuevo o actualizar el existente"
              fi
            fi
          else
            echo "‚úÖ DB Subnet Group no existe, Terraform lo crear√°"
          fi
          
          # Importar DynamoDB Table si existe
          TABLE_NAME="${PROJECT_NAME}-${ENV}-appointments"
          if aws dynamodb describe-table --table-name "$TABLE_NAME" --region "$REGION" >/dev/null 2>&1; then
            echo "üì¶ DynamoDB Table existe: $TABLE_NAME"
            if terraform state show aws_dynamodb_table.appointments >/dev/null 2>&1; then
              echo "‚úÖ DynamoDB Table ya est√° en el estado de Terraform"
            else
              echo "üîÑ Importando DynamoDB Table..."
              terraform import aws_dynamodb_table.appointments "$TABLE_NAME" 2>&1 || \
                echo "‚ö†Ô∏è  No se pudo importar (continuando...)"
            fi
          else
            echo "‚úÖ DynamoDB Table no existe, Terraform la crear√°"
          fi
          
          # Importar EventBridge Bus si existe
          BUS_NAME="${PROJECT_NAME}-${ENV}-bus"
          if aws events describe-event-bus --name "$BUS_NAME" --region "$REGION" >/dev/null 2>&1; then
            echo "üì¶ EventBridge Bus existe: $BUS_NAME"
            if terraform state show aws_cloudwatch_event_bus.main >/dev/null 2>&1; then
              echo "‚úÖ EventBridge Bus ya est√° en el estado de Terraform"
            else
              echo "üîÑ Importando EventBridge Bus..."
              terraform import aws_cloudwatch_event_bus.main "$BUS_NAME" 2>&1 || \
                echo "‚ö†Ô∏è  No se pudo importar (continuando...)"
            fi
          else
            echo "‚úÖ EventBridge Bus no existe, Terraform lo crear√°"
          fi
          
          # Importar Secrets Manager si existen
          SECRETS=(
            "${PROJECT_NAME}-${ENV}-rds-peru-credentials"
            "${PROJECT_NAME}-${ENV}-rds-chile-credentials"
          )
          
          for SECRET_NAME in "${SECRETS[@]}"; do
            if aws secretsmanager describe-secret --secret-id "$SECRET_NAME" --region "$REGION" >/dev/null 2>&1; then
              echo "üì¶ Secret existe: $SECRET_NAME"
              
              # Determinar el nombre del recurso en Terraform
              if [[ "$SECRET_NAME" == *"peru"* ]]; then
                TERRAFORM_RESOURCE="aws_secretsmanager_secret.rds_peru"
              else
                TERRAFORM_RESOURCE="aws_secretsmanager_secret.rds_chile"
              fi
              
              if terraform state show "$TERRAFORM_RESOURCE" >/dev/null 2>&1; then
                echo "‚úÖ Secret ya est√° en el estado de Terraform"
              else
                echo "üîÑ Importando Secret..."
                terraform import "$TERRAFORM_RESOURCE" "$SECRET_NAME" 2>&1 || \
                  echo "‚ö†Ô∏è  No se pudo importar (continuando...)"
              fi
            else
              echo "‚úÖ Secret $SECRET_NAME no existe, Terraform lo crear√°"
            fi
          done
          
          echo "‚úÖ Proceso de importaci√≥n completado"

      - name: Terraform Plan (after import)
        if: github.event_name == 'push' || github.event_name == 'workflow_dispatch'
        working-directory: ./terraform
        run: |
          # Crear plan DESPU√âS de la importaci√≥n para incluir recursos importados
          terraform plan \
            -var="environment=${{ steps.determine-env.outputs.environment }}" \
            -var="rds_pe_master_username=${{ secrets.RDS_PE_USERNAME }}" \
            -var="rds_pe_master_password=${{ secrets.RDS_PE_PASSWORD }}" \
            -var="rds_cl_master_username=${{ secrets.RDS_CL_USERNAME }}" \
            -var="rds_cl_master_password=${{ secrets.RDS_CL_PASSWORD }}" \
            -out=tfplan

      - name: Terraform Apply
        if: github.event_name == 'push' || github.event_name == 'workflow_dispatch'
        working-directory: ./terraform
        run: |
          # Aplicar el plan creado DESPU√âS de la importaci√≥n (incluye recursos importados)
          terraform apply -auto-approve tfplan

      - name: Get Terraform Outputs
        id: tf-outputs
        if: github.event_name == 'push' || github.event_name == 'workflow_dispatch'
        working-directory: ./terraform
        run: |
          # Verificar que el state tiene outputs
          if ! terraform output vpc_id > /dev/null 2>&1; then
            echo "‚ùå Error: Terraform outputs no est√°n disponibles"
            echo "Esto puede ocurrir si Terraform apply fall√≥"
            exit 1
          fi
          
          # Obtener outputs
          echo "vpc_id=$(terraform output -raw vpc_id)" >> $GITHUB_OUTPUT
          # private_subnet_ids es una lista, usar -json y convertir a string separado por comas
          PRIVATE_SUBNETS=$(terraform output -json private_subnet_ids | jq -r 'join(",")')
          echo "private_subnet_ids=$PRIVATE_SUBNETS" >> $GITHUB_OUTPUT
          echo "lambda_sg_id=$(terraform output -raw lambda_security_group_id)" >> $GITHUB_OUTPUT
          echo "dynamodb_table=$(terraform output -raw dynamodb_table_name)" >> $GITHUB_OUTPUT
          echo "dynamodb_table_arn=$(terraform output -raw dynamodb_table_arn)" >> $GITHUB_OUTPUT
          echo "sns_peru_arn=$(terraform output -raw sns_topic_arn_peru)" >> $GITHUB_OUTPUT
          echo "sns_chile_arn=$(terraform output -raw sns_topic_arn_chile)" >> $GITHUB_OUTPUT
          echo "sqs_queue_url_peru=$(terraform output -raw sqs_queue_url_peru)" >> $GITHUB_OUTPUT
          echo "sqs_queue_url_chile=$(terraform output -raw sqs_queue_url_chile)" >> $GITHUB_OUTPUT
          echo "sqs_queue_arn_peru=$(terraform output -raw sqs_queue_arn_peru)" >> $GITHUB_OUTPUT
          echo "sqs_queue_arn_chile=$(terraform output -raw sqs_queue_arn_chile)" >> $GITHUB_OUTPUT
          echo "sqs_completion_queue_url=$(terraform output -raw sqs_completion_queue_url)" >> $GITHUB_OUTPUT
          echo "sqs_completion_queue_arn=$(terraform output -raw sqs_completion_queue_arn)" >> $GITHUB_OUTPUT
          echo "eventbridge_bus_name=$(terraform output -raw eventbridge_bus_name)" >> $GITHUB_OUTPUT
          echo "rds_peru_secret_arn=$(terraform output -raw rds_peru_secret_arn)" >> $GITHUB_OUTPUT
          echo "rds_chile_secret_arn=$(terraform output -raw rds_chile_secret_arn)" >> $GITHUB_OUTPUT
          
          # Mostrar outputs para debug
          echo "‚úÖ Terraform outputs obtenidos correctamente"
          echo "VPC ID: $(terraform output -raw vpc_id)"

  # ===============================================
  # Deploy Lambda Functions (SAM)
  # ===============================================
  deploy-sam:
    name: Deploy Lambda Functions (SAM)
    needs: [test-and-build, deploy-terraform]
    runs-on: ubuntu-latest
    if: github.event_name == 'push' || github.event_name == 'workflow_dispatch'
    environment: 
      name: ${{ github.ref == 'refs/heads/main' && 'prod' || github.ref == 'refs/heads/develop' && 'staging' || 'dev' }}
    
    outputs:
      api_url: ${{ steps.sam-deploy.outputs.api_url }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: package-lock.json

      - name: Download build artifacts
        uses: actions/download-artifact@v4
        with:
          name: dist
          path: dist/

      - name: Setup AWS SAM
        uses: aws-actions/setup-sam@v2
        with:
          use-installer: true

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Determine environment
        id: determine-env
        run: |
          if [[ "${{ github.ref }}" == "refs/heads/main" ]]; then
            echo "environment=prod" >> $GITHUB_OUTPUT
          elif [[ "${{ github.ref }}" == "refs/heads/develop" ]]; then
            echo "environment=staging" >> $GITHUB_OUTPUT
          else
            echo "environment=dev" >> $GITHUB_OUTPUT
          fi

      - name: SAM Build
        working-directory: ./sam
        run: sam build

      - name: SAM Deploy
        id: sam-deploy
        working-directory: ./sam
        run: |
          sam deploy \
            --stack-name agendamiento-citas-${{ steps.determine-env.outputs.environment }} \
            --resolve-s3 \
            --parameter-overrides \
              Environment=${{ steps.determine-env.outputs.environment }} \
              VpcId=${{ needs.deploy-terraform.outputs.vpc_id }} \
              PrivateSubnetIds="${{ needs.deploy-terraform.outputs.private_subnet_ids }}" \
              LambdaSecurityGroupId=${{ needs.deploy-terraform.outputs.lambda_sg_id }} \
              DynamoDBTableName=${{ needs.deploy-terraform.outputs.dynamodb_table }} \
              DynamoDBTableArn=${{ needs.deploy-terraform.outputs.dynamodb_table_arn }} \
              SNSTopicArnPeru=${{ needs.deploy-terraform.outputs.sns_peru_arn }} \
              SNSTopicArnChile=${{ needs.deploy-terraform.outputs.sns_chile_arn }} \
              SQSQueueUrlPeru=${{ needs.deploy-terraform.outputs.sqs_queue_url_peru }} \
              SQSQueueUrlChile=${{ needs.deploy-terraform.outputs.sqs_queue_url_chile }} \
              SQSQueueArnPeru=${{ needs.deploy-terraform.outputs.sqs_queue_arn_peru }} \
              SQSQueueArnChile=${{ needs.deploy-terraform.outputs.sqs_queue_arn_chile }} \
              SQSCompletionQueueUrl=${{ needs.deploy-terraform.outputs.sqs_completion_queue_url }} \
              SQSCompletionQueueArn=${{ needs.deploy-terraform.outputs.sqs_completion_queue_arn }} \
              EventBridgeBusName=${{ needs.deploy-terraform.outputs.eventbridge_bus_name }} \
              RDSPeruSecretArn=${{ needs.deploy-terraform.outputs.rds_peru_secret_arn }} \
              RDSChileSecretArn=${{ needs.deploy-terraform.outputs.rds_chile_secret_arn }} \
            --capabilities CAPABILITY_IAM \
            --no-confirm-changeset \
            --no-fail-on-empty-changeset

          # Get API URL
          API_URL=$(aws cloudformation describe-stacks \
            --stack-name agendamiento-citas-${{ steps.determine-env.outputs.environment }} \
            --query 'Stacks[0].Outputs[?OutputKey==`ApiUrl`].OutputValue' \
            --output text)
          
          echo "api_url=$API_URL" >> $GITHUB_OUTPUT

      - name: Display API URL
        run: |
          echo "üöÄ API deployed successfully!"
          echo "üìç API URL: ${{ steps.sam-deploy.outputs.api_url }}"

  # ===============================================
  # Initialize Databases
  # ===============================================
  init-databases:
    name: Initialize RDS Databases
    needs: [deploy-terraform]
    runs-on: ubuntu-latest
    if: github.event_name == 'push' && (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/develop')
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Install MySQL Client
        run: |
          sudo apt-get update
          sudo apt-get install -y mysql-client

      - name: Initialize Peru Database
        run: |
          mysql -h ${{ secrets.RDS_PE_HOST }} \
                -u ${{ secrets.RDS_PE_USERNAME }} \
                -p${{ secrets.RDS_PE_PASSWORD }} \
                ${{ secrets.RDS_PE_DATABASE }} \
                < docs/database-schema.sql

      - name: Initialize Chile Database
        run: |
          mysql -h ${{ secrets.RDS_CL_HOST }} \
                -u ${{ secrets.RDS_CL_USERNAME }} \
                -p${{ secrets.RDS_CL_PASSWORD }} \
                ${{ secrets.RDS_CL_DATABASE }} \
                < docs/database-schema.sql

  # ===============================================
  # Integration Tests
  # ===============================================
  integration-tests:
    name: Integration Tests
    needs: [deploy-sam]
    runs-on: ubuntu-latest
    if: github.event_name == 'push' || github.event_name == 'workflow_dispatch'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Test API - Create Appointment
        run: |
          API_URL="${{ needs.deploy-sam.outputs.api_url }}"
          
          RESPONSE=$(curl -s -X POST "$API_URL/appointments" \
            -H "Content-Type: application/json" \
            -d '{"insuredId": "12345", "scheduleId": 100, "countryISO": "PE"}')
          
          echo "Response: $RESPONSE"
          
          # Verificar que la respuesta contiene appointmentId
          if echo "$RESPONSE" | jq -e '.appointmentId' > /dev/null; then
            echo "‚úÖ Create appointment test passed"
          else
            echo "‚ùå Create appointment test failed"
            exit 1
          fi

      - name: Test API - List Appointments
        run: |
          API_URL="${{ needs.deploy-sam.outputs.api_url }}"
          
          RESPONSE=$(curl -s "$API_URL/appointments/12345")
          
          echo "Response: $RESPONSE"
          
          # Verificar que la respuesta contiene appointments
          if echo "$RESPONSE" | jq -e '.appointments' > /dev/null; then
            echo "‚úÖ List appointments test passed"
          else
            echo "‚ùå List appointments test failed"
            exit 1
          fi

  # ===============================================
  # Notification
  # ===============================================
  notify:
    name: Send Notification
    needs: [deploy-sam, integration-tests]
    runs-on: ubuntu-latest
    if: always() && (github.event_name == 'push' || github.event_name == 'workflow_dispatch')
    
    steps:
      - name: Send success notification
        if: needs.integration-tests.result == 'success'
        run: |
          echo "‚úÖ Deployment successful!"
          echo "üöÄ API URL: ${{ needs.deploy-sam.outputs.api_url }}"
          echo "üåç Environment: ${{ github.ref }}"

      - name: Send failure notification
        if: needs.integration-tests.result != 'success'
        run: |
          echo "‚ùå Deployment failed!"
          echo "üîç Check the logs for details"

