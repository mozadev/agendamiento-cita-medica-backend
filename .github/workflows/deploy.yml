name: Deploy Infrastructure and Application

on:
  push:
    branches:
      - main
      - develop
  pull_request:
    branches:
      - main
      - develop
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment to deploy'
        required: true
        default: 'dev'
        type: choice
        options:
          - dev
          - staging
          - prod

env:
  AWS_REGION: us-east-1
  NODE_VERSION: '20'
  TERRAFORM_VERSION: '1.6.0'

jobs:
  # ===============================================
  # Test y Build
  # ===============================================
  test-and-build:
    name: Test and Build
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Verify package-lock.json exists
        run: |
          if [ ! -f package-lock.json ]; then
            echo "‚ùå Error: package-lock.json not found!"
            ls -la
            exit 1
          fi
          echo "‚úÖ package-lock.json found"
          ls -lh package-lock.json

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: package-lock.json

      - name: Install dependencies
        run: npm ci

      - name: Run linter
        run: npm run lint || echo "Linting completed"

      - name: Run tests
        run: npm test

      - name: Build TypeScript
        run: npm run build

      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: dist
          path: dist/
          retention-days: 7

      - name: Upload coverage
        uses: codecov/codecov-action@v3
        with:
          files: ./coverage/lcov.info
          flags: unittests
          name: codecov-umbrella
          fail_ci_if_error: false

  # ===============================================
  # Deploy Infrastructure (Terraform)
  # ===============================================
  deploy-terraform:
    name: Deploy Infrastructure (Terraform)
    needs: test-and-build
    runs-on: ubuntu-latest
    environment: 
      name: ${{ github.ref == 'refs/heads/main' && 'prod' || github.ref == 'refs/heads/develop' && 'staging' || 'dev' }}
    
    outputs:
      vpc_id: ${{ steps.tf-outputs.outputs.vpc_id }}
      private_subnet_ids: ${{ steps.tf-outputs.outputs.private_subnet_ids }}
      lambda_sg_id: ${{ steps.tf-outputs.outputs.lambda_sg_id }}
      dynamodb_table: ${{ steps.tf-outputs.outputs.dynamodb_table }}
      dynamodb_table_arn: ${{ steps.tf-outputs.outputs.dynamodb_table_arn }}
      sns_peru_arn: ${{ steps.tf-outputs.outputs.sns_peru_arn }}
      sns_chile_arn: ${{ steps.tf-outputs.outputs.sns_chile_arn }}
      sqs_queue_url_peru: ${{ steps.tf-outputs.outputs.sqs_queue_url_peru }}
      sqs_queue_url_chile: ${{ steps.tf-outputs.outputs.sqs_queue_url_chile }}
      sqs_queue_arn_peru: ${{ steps.tf-outputs.outputs.sqs_queue_arn_peru }}
      sqs_queue_arn_chile: ${{ steps.tf-outputs.outputs.sqs_queue_arn_chile }}
      sqs_completion_queue_url: ${{ steps.tf-outputs.outputs.sqs_completion_queue_url }}
      sqs_completion_queue_arn: ${{ steps.tf-outputs.outputs.sqs_completion_queue_arn }}
      eventbridge_bus_name: ${{ steps.tf-outputs.outputs.eventbridge_bus_name }}
      rds_peru_secret_arn: ${{ steps.tf-outputs.outputs.rds_peru_secret_arn }}
      rds_chile_secret_arn: ${{ steps.tf-outputs.outputs.rds_chile_secret_arn }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install jq (if needed)
        run: |
          if ! command -v jq >/dev/null 2>&1; then
            echo "üì¶ Instalando jq..."
            sudo apt-get update && sudo apt-get install -y jq
          else
            echo "‚úÖ jq ya est√° instalado"
          fi
          jq --version

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TERRAFORM_VERSION }}
          terraform_wrapper: false

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Determine environment
        id: determine-env
        run: |
          if [[ "${{ github.ref }}" == "refs/heads/main" ]]; then
            echo "environment=prod" >> $GITHUB_OUTPUT
          elif [[ "${{ github.ref }}" == "refs/heads/develop" ]]; then
            echo "environment=staging" >> $GITHUB_OUTPUT
          else
            echo "environment=dev" >> $GITHUB_OUTPUT
          fi

      - name: Terraform Init
        working-directory: ./terraform
        run: terraform init

      - name: Terraform Format Check
        working-directory: ./terraform
        run: terraform fmt -check || true

      - name: Terraform Validate
        working-directory: ./terraform
        run: terraform validate

      - name: Cleanup Duplicate VPCs
        if: github.event_name == 'push' || github.event_name == 'workflow_dispatch'
        continue-on-error: true
        run: |
          ENV="${{ steps.determine-env.outputs.environment }}"
          PROJECT_NAME="agendamiento-v2"
          REGION="us-east-1"
          VPC_NAME="${PROJECT_NAME}-${ENV}-vpc"
          
          echo "üßπ Limpiando VPCs duplicadas/viejas..."
          
          # Obtener todas las VPCs con el mismo nombre
          VPC_IDS=$(aws ec2 describe-vpcs \
            --region "$REGION" \
            --filters "Name=tag:Name,Values=$VPC_NAME" \
            --query 'Vpcs[].[VpcId,CreationDate]' \
            --output text | sort -k2 -r)
          
          if [ -z "$VPC_IDS" ]; then
            echo "‚úÖ No hay VPCs duplicadas con nombre: $VPC_NAME"
          else
            echo "üìä VPCs encontradas con nombre $VPC_NAME:"
            echo "$VPC_IDS" | while read VPC_ID CREATION_DATE; do
              echo "  - $VPC_ID (creada: $CREATION_DATE)"
            done
            
            # Contar VPCs
            VPC_COUNT=$(echo "$VPC_IDS" | wc -l | tr -d ' ')
            
            if [ "$VPC_COUNT" -gt 1 ]; then
              echo ""
              echo "üóëÔ∏è  Eliminando VPCs duplicadas (manteniendo la m√°s reciente)..."
              
              # Eliminar todas excepto la primera (m√°s reciente)
              echo "$VPC_IDS" | tail -n +2 | while read VPC_ID CREATION_DATE; do
                echo "  Eliminando VPC duplicada: $VPC_ID"
                
                # Verificar si tiene recursos en uso
                RDS_COUNT=$(aws rds describe-db-instances --region "$REGION" \
                  --query "length(DBInstances[?DBSubnetGroup.VpcId=='$VPC_ID'])" \
                  --output text 2>/dev/null || echo "0")
                
                if [ "$RDS_COUNT" -gt 0 ]; then
                  echo "    ‚ö†Ô∏è  VPC tiene $RDS_COUNT instancias RDS, no se eliminar√°"
                else
                  # Eliminar recursos de la VPC
                  echo "    üóëÔ∏è  Eliminando recursos de VPC $VPC_ID..."
                  
                  # Eliminar NAT Gateways
                  NAT_GWS=$(aws ec2 describe-nat-gateways --region "$REGION" \
                    --filter "Name=vpc-id,Values=$VPC_ID" "Name=state,Values=available,pending" \
                    --query 'NatGateways[].NatGatewayId' --output text 2>/dev/null || echo "")
                  for NAT in $NAT_GWS; do
                    aws ec2 delete-nat-gateway --nat-gateway-id "$NAT" --region "$REGION" >/dev/null 2>&1 && \
                      echo "      ‚úÖ NAT Gateway $NAT elimin√°ndose..." || true
                  done
                  
                  # Desconectar y eliminar Internet Gateways
                  IGW=$(aws ec2 describe-internet-gateways --region "$REGION" \
                    --filters "Name=attachment.vpc-id,Values=$VPC_ID" \
                    --query 'InternetGateways[0].InternetGatewayId' --output text 2>/dev/null || echo "None")
                  if [ "$IGW" != "None" ] && [ ! -z "$IGW" ]; then
                    aws ec2 detach-internet-gateway --internet-gateway-id "$IGW" --vpc-id "$VPC_ID" --region "$REGION" >/dev/null 2>&1 || true
                    aws ec2 delete-internet-gateway --internet-gateway-id "$IGW" --region "$REGION" >/dev/null 2>&1 && \
                      echo "      ‚úÖ Internet Gateway eliminado" || true
                  fi
                  
                  # Eliminar Subnets
                  SUBNETS=$(aws ec2 describe-subnets --region "$REGION" \
                    --filters "Name=vpc-id,Values=$VPC_ID" \
                    --query 'Subnets[].SubnetId' --output text 2>/dev/null || echo "")
                  for SUBNET in $SUBNETS; do
                    aws ec2 delete-subnet --subnet-id "$SUBNET" --region "$REGION" >/dev/null 2>&1 || true
                  done
                  [ ! -z "$SUBNETS" ] && echo "      ‚úÖ Subnets eliminadas" || true
                  
                  # Eliminar Security Groups (excepto default)
                  SGS=$(aws ec2 describe-security-groups --region "$REGION" \
                    --filters "Name=vpc-id,Values=$VPC_ID" \
                    --query 'SecurityGroups[?GroupName!=`default`].GroupId' --output text 2>/dev/null || echo "")
                  for SG in $SGS; do
                    aws ec2 delete-security-group --group-id "$SG" --region "$REGION" >/dev/null 2>&1 || true
                  done
                  [ ! -z "$SGS" ] && echo "      ‚úÖ Security Groups eliminados" || true
                  
                  # Eliminar Route Tables (excepto main)
                  RTS=$(aws ec2 describe-route-tables --region "$REGION" \
                    --filters "Name=vpc-id,Values=$VPC_ID" \
                    --query 'RouteTables[?Associations[0].Main!=`true`].RouteTableId' --output text 2>/dev/null || echo "")
                  for RT in $RTS; do
                    # Desasociar de subnets
                    ASSOCS=$(aws ec2 describe-route-tables --region "$REGION" \
                      --route-table-ids "$RT" \
                      --query 'RouteTables[0].Associations[?SubnetId!=`null`].RouteTableAssociationId' \
                      --output text 2>/dev/null || echo "")
                    for ASSOC in $ASSOCS; do
                      aws ec2 disassociate-route-table --association-id "$ASSOC" --region "$REGION" >/dev/null 2>&1 || true
                    done
                    aws ec2 delete-route-table --route-table-id "$RT" --region "$REGION" >/dev/null 2>&1 || true
                  done
                  [ ! -z "$RTS" ] && echo "      ‚úÖ Route Tables eliminadas" || true
                  
                  # Intentar eliminar VPC
                  sleep 5  # Esperar a que recursos se eliminen
                  if aws ec2 delete-vpc --vpc-id "$VPC_ID" --region "$REGION" 2>&1; then
                    echo "      ‚úÖ VPC $VPC_ID eliminada exitosamente"
                  else
                    echo "      ‚ö†Ô∏è  VPC $VPC_ID a√∫n tiene dependencias (se reintentar√° en pr√≥ximo deploy)"
                  fi
                fi
              done
            else
              echo "‚úÖ Solo hay 1 VPC, no hay duplicadas"
            fi
          fi
          
          # Verificar l√≠mite de VPCs
          TOTAL_VPCS=$(aws ec2 describe-vpcs --region "$REGION" --query 'length(Vpcs)' --output text)
          echo ""
          echo "üìä Total VPCs en cuenta: $TOTAL_VPCS / 5 (l√≠mite)"
          
          if [ "$TOTAL_VPCS" -ge 5 ]; then
            echo "‚ö†Ô∏è  L√≠mite de VPCs alcanzado. Limpiando VPCs viejas de proyectos anteriores..."
            
            # Buscar VPCs viejas de agendamiento-citas (proyecto anterior)
            OLD_VPCS=$(aws ec2 describe-vpcs \
              --region "$REGION" \
              --filters "Name=tag:Name,Values=agendamiento-citas-*-vpc" \
              --query 'Vpcs[].[VpcId,CreationDate]' \
              --output text | sort -k2)
            
            if [ ! -z "$OLD_VPCS" ]; then
              echo "üóëÔ∏è  Eliminando VPCs viejas de agendamiento-citas..."
              echo "$OLD_VPCS" | head -n 1 | while read OLD_VPC_ID CREATION_DATE; do
                echo "  Eliminando VPC vieja: $OLD_VPC_ID"
                
                # Verificar si tiene RDS
                RDS_COUNT=$(aws rds describe-db-instances --region "$REGION" \
                  --query "length(DBInstances[?DBSubnetGroup.VpcId=='$OLD_VPC_ID'])" \
                  --output text 2>/dev/null || echo "0")
                
                if [ "$RDS_COUNT" -gt 0 ]; then
                  echo "    ‚ö†Ô∏è  VPC tiene $RDS_COUNT instancias RDS, no se eliminar√°"
                else
                  # Eliminar recursos (misma l√≥gica que arriba)
                  echo "    üóëÔ∏è  Eliminando recursos..."
                  
                  # NAT Gateways
                  NAT_GWS=$(aws ec2 describe-nat-gateways --region "$REGION" \
                    --filter "Name=vpc-id,Values=$OLD_VPC_ID" "Name=state,Values=available,pending" \
                    --query 'NatGateways[].NatGatewayId' --output text 2>/dev/null || echo "")
                  for NAT in $NAT_GWS; do
                    aws ec2 delete-nat-gateway --nat-gateway-id "$NAT" --region "$REGION" >/dev/null 2>&1 || true
                  done
                  
                  # Internet Gateways
                  IGW=$(aws ec2 describe-internet-gateways --region "$REGION" \
                    --filters "Name=attachment.vpc-id,Values=$OLD_VPC_ID" \
                    --query 'InternetGateways[0].InternetGatewayId' --output text 2>/dev/null || echo "None")
                  if [ "$IGW" != "None" ] && [ ! -z "$IGW" ]; then
                    aws ec2 detach-internet-gateway --internet-gateway-id "$IGW" --vpc-id "$OLD_VPC_ID" --region "$REGION" >/dev/null 2>&1 || true
                    aws ec2 delete-internet-gateway --internet-gateway-id "$IGW" --region "$REGION" >/dev/null 2>&1 || true
                  fi
                  
                  # Subnets, Security Groups, Route Tables (simplificado)
                  aws ec2 describe-subnets --region "$REGION" --filters "Name=vpc-id,Values=$OLD_VPC_ID" \
                    --query 'Subnets[].SubnetId' --output text 2>/dev/null | tr '\t' '\n' | \
                    xargs -I {} aws ec2 delete-subnet --subnet-id {} --region "$REGION" >/dev/null 2>&1 || true
                  
                  aws ec2 describe-security-groups --region "$REGION" \
                    --filters "Name=vpc-id,Values=$OLD_VPC_ID" \
                    --query 'SecurityGroups[?GroupName!=`default`].GroupId' --output text 2>/dev/null | \
                    tr '\t' '\n' | xargs -I {} aws ec2 delete-security-group --group-id {} --region "$REGION" >/dev/null 2>&1 || true
                  
                  # Intentar eliminar VPC
                  sleep 5
                  if aws ec2 delete-vpc --vpc-id "$OLD_VPC_ID" --region "$REGION" 2>&1; then
                    echo "    ‚úÖ VPC $OLD_VPC_ID eliminada"
                  else
                    echo "    ‚ö†Ô∏è  VPC $OLD_VPC_ID a√∫n tiene dependencias"
                  fi
                fi
              done
            fi
          fi
          
          # Limpiar Elastic IPs no utilizados
          echo ""
          echo "üßπ Limpiando Elastic IPs no utilizados..."
          UNUSED_EIPS=$(aws ec2 describe-addresses \
            --region "$REGION" \
            --query 'Addresses[?AssociationId==`null`].AllocationId' \
            --output text 2>/dev/null || echo "")
          
          if [ ! -z "$UNUSED_EIPS" ]; then
            EIP_COUNT=$(echo "$UNUSED_EIPS" | wc -w | tr -d ' ')
            echo "üìä Elastic IPs sin asociar encontrados: $EIP_COUNT"
            
            # Liberar hasta dejar espacio para 2 nuevos (para NAT Gateways)
            CURRENT_EIPS=$(aws ec2 describe-addresses --region "$REGION" --query 'length(Addresses)' --output text)
            if [ "$CURRENT_EIPS" -ge 5 ]; then
              echo "‚ö†Ô∏è  L√≠mite de Elastic IPs alcanzado ($CURRENT_EIPS/5). Liberando no utilizados..."
              echo "$UNUSED_EIPS" | tr ' ' '\n' | head -n $((CURRENT_EIPS - 3)) | while read EIP; do
                echo "  Liberando: $EIP"
                aws ec2 release-address --allocation-id "$EIP" --region "$REGION" >/dev/null 2>&1 || true
              done
              echo "‚úÖ Elastic IPs no utilizados liberados"
            else
              echo "‚úÖ Hay espacio suficiente para Elastic IPs ($CURRENT_EIPS/5)"
            fi
          else
            echo "‚úÖ No hay Elastic IPs sin asociar"
          fi
          
          echo "‚úÖ Limpieza de VPCs y recursos completada"

      - name: Import Existing Resources (if any)
        if: github.event_name == 'push' || github.event_name == 'workflow_dispatch'
        working-directory: ./terraform
        continue-on-error: true
        env:
          # Pasar variables de RDS como environment variables para terraform import
          TF_VAR_environment: ${{ steps.determine-env.outputs.environment }}
          TF_VAR_rds_pe_master_username: ${{ secrets.RDS_PE_USERNAME }}
          TF_VAR_rds_pe_master_password: ${{ secrets.RDS_PE_PASSWORD }}
          TF_VAR_rds_cl_master_username: ${{ secrets.RDS_CL_USERNAME }}
          TF_VAR_rds_cl_master_password: ${{ secrets.RDS_CL_PASSWORD }}
        run: |
          # Determinar nombre del proyecto basado en environment
          ENV="${{ steps.determine-env.outputs.environment }}"
          PROJECT_NAME="agendamiento-v2"
          REGION="us-east-1"
          
          echo "üîç Verificando recursos existentes que pueden necesitar importaci√≥n..."
          
          # Importar VPC si existe
          VPC_NAME="${PROJECT_NAME}-${ENV}-vpc"
          EXISTING_VPC=$(aws ec2 describe-vpcs \
            --region "$REGION" \
            --filters "Name=tag:Name,Values=$VPC_NAME" \
            --query 'Vpcs[0].VpcId' \
            --output text)
          
          if [ ! -z "$EXISTING_VPC" ] && [ "$EXISTING_VPC" != "None" ]; then
            echo "üì¶ VPC existe: $EXISTING_VPC ($VPC_NAME)"
            if terraform state show aws_vpc.main >/dev/null 2>&1; then
              echo "‚úÖ VPC ya est√° en el estado de Terraform"
            else
              echo "üîÑ Importando VPC al estado de Terraform..."
              terraform import aws_vpc.main "$EXISTING_VPC" 2>&1 || \
                echo "‚ö†Ô∏è  No se pudo importar (continuando...)"
            fi
            
            # Importar recursos relacionados de la VPC
            echo "üîÑ Importando recursos relacionados de la VPC..."
            
            # Internet Gateway
            IGW_ID=$(aws ec2 describe-internet-gateways \
              --region "$REGION" \
              --filters "Name=attachment.vpc-id,Values=$EXISTING_VPC" \
              --query 'InternetGateways[0].InternetGatewayId' \
              --output text 2>/dev/null || echo "None")
            if [ "$IGW_ID" != "None" ] && [ ! -z "$IGW_ID" ]; then
              if ! terraform state show aws_internet_gateway.main >/dev/null 2>&1; then
                terraform import aws_internet_gateway.main "$IGW_ID" 2>&1 || \
                  echo "  ‚ö†Ô∏è  No se pudo importar Internet Gateway"
              fi
            fi
            
            # Subnets (public, private, database) - importar por nombre
            for SUBNET_TYPE in "public" "private" "database"; do
              for AZ_INDEX in "1" "2"; do
                if [ "$AZ_INDEX" == "1" ]; then
                  AZ_SUFFIX="a"
                  TERRAFORM_INDEX="0"
                else
                  AZ_SUFFIX="b"
                  TERRAFORM_INDEX="1"
                fi
                
                SUBNET_NAME_PATTERN="${PROJECT_NAME}-${ENV}-${SUBNET_TYPE}-subnet-${AZ_INDEX}"
                SUBNET_ID=$(aws ec2 describe-subnets \
                  --region "$REGION" \
                  --filters "Name=vpc-id,Values=$EXISTING_VPC" "Name=tag:Name,Values=$SUBNET_NAME_PATTERN" \
                  --query 'Subnets[0].SubnetId' \
                  --output text 2>/dev/null || echo "None")
                
                if [ "$SUBNET_ID" != "None" ] && [ ! -z "$SUBNET_ID" ]; then
                  TERRAFORM_RESOURCE="aws_subnet.${SUBNET_TYPE}[${TERRAFORM_INDEX}]"
                  if ! terraform state show "$TERRAFORM_RESOURCE" >/dev/null 2>&1; then
                    terraform import "$TERRAFORM_RESOURCE" "$SUBNET_ID" 2>&1 || \
                      echo "  ‚ö†Ô∏è  No se pudo importar subnet $SUBNET_ID"
                  fi
                fi
              done
            done
            
            # Security Groups
            SG_LAMBDA=$(aws ec2 describe-security-groups \
              --region "$REGION" \
              --filters "Name=vpc-id,Values=$EXISTING_VPC" "Name=tag:Name,Values=${PROJECT_NAME}-${ENV}-lambda-sg" \
              --query 'SecurityGroups[0].GroupId' \
              --output text 2>/dev/null || echo "None")
            if [ "$SG_LAMBDA" != "None" ] && [ ! -z "$SG_LAMBDA" ]; then
              if ! terraform state show aws_security_group.lambda >/dev/null 2>&1; then
                terraform import aws_security_group.lambda "$SG_LAMBDA" 2>&1 || \
                  echo "  ‚ö†Ô∏è  No se pudo importar Security Group Lambda"
              fi
            fi
            
            SG_RDS=$(aws ec2 describe-security-groups \
              --region "$REGION" \
              --filters "Name=vpc-id,Values=$EXISTING_VPC" "Name=tag:Name,Values=${PROJECT_NAME}-${ENV}-rds-sg" \
              --query 'SecurityGroups[0].GroupId' \
              --output text 2>/dev/null || echo "None")
            if [ "$SG_RDS" != "None" ] && [ ! -z "$SG_RDS" ]; then
              if ! terraform state show aws_security_group.rds >/dev/null 2>&1; then
                terraform import aws_security_group.rds "$SG_RDS" 2>&1 || \
                  echo "  ‚ö†Ô∏è  No se pudo importar Security Group RDS"
              fi
            fi
            
            # Route Tables
            RT_PUBLIC=$(aws ec2 describe-route-tables \
              --region "$REGION" \
              --filters "Name=vpc-id,Values=$EXISTING_VPC" "Name=tag:Name,Values=${PROJECT_NAME}-${ENV}-public-rt" \
              --query 'RouteTables[0].RouteTableId' \
              --output text 2>/dev/null || echo "None")
            if [ "$RT_PUBLIC" != "None" ] && [ ! -z "$RT_PUBLIC" ]; then
              if ! terraform state show aws_route_table.public >/dev/null 2>&1; then
                terraform import aws_route_table.public "$RT_PUBLIC" 2>&1 || \
                  echo "  ‚ö†Ô∏è  No se pudo importar Route Table public"
              fi
            fi
            
            RT_DATABASE=$(aws ec2 describe-route-tables \
              --region "$REGION" \
              --filters "Name=vpc-id,Values=$EXISTING_VPC" "Name=tag:Name,Values=${PROJECT_NAME}-${ENV}-database-rt" \
              --query 'RouteTables[0].RouteTableId' \
              --output text 2>/dev/null || echo "None")
            if [ "$RT_DATABASE" != "None" ] && [ ! -z "$RT_DATABASE" ]; then
              if ! terraform state show aws_route_table.database >/dev/null 2>&1; then
                terraform import aws_route_table.database "$RT_DATABASE" 2>&1 || \
                  echo "  ‚ö†Ô∏è  No se pudo importar Route Table database"
              fi
            fi
            
            # Route Tables privadas
            for RT_INDEX in "0" "1"; do
              RT_NAME="${PROJECT_NAME}-${ENV}-private-rt-$((RT_INDEX + 1))"
              RT_PRIVATE=$(aws ec2 describe-route-tables \
                --region "$REGION" \
                --filters "Name=vpc-id,Values=$EXISTING_VPC" "Name=tag:Name,Values=$RT_NAME" \
                --query 'RouteTables[0].RouteTableId' \
                --output text 2>/dev/null || echo "None")
              
              if [ "$RT_PRIVATE" != "None" ] && [ ! -z "$RT_PRIVATE" ]; then
                TERRAFORM_RESOURCE="aws_route_table.private[${RT_INDEX}]"
                if ! terraform state show "$TERRAFORM_RESOURCE" >/dev/null 2>&1; then
                  terraform import "$TERRAFORM_RESOURCE" "$RT_PRIVATE" 2>&1 || \
                    echo "  ‚ö†Ô∏è  No se pudo importar Route Table private[$RT_INDEX]"
                fi
              fi
            done
            
            # Route Table Associations (public, private, database)
            # M√©todo robusto: obtener todas las route tables y buscar asociaciones por subnet
            echo "  üîç Importando Route Table Associations..."
            
            for SUBNET_TYPE in "public" "private" "database"; do
              for AZ_INDEX in "1" "2"; do
                if [ "$AZ_INDEX" == "1" ]; then
                  TERRAFORM_INDEX="0"
                else
                  TERRAFORM_INDEX="1"
                fi
                
                SUBNET_NAME_PATTERN="${PROJECT_NAME}-${ENV}-${SUBNET_TYPE}-subnet-${AZ_INDEX}"
                SUBNET_ID=$(aws ec2 describe-subnets \
                  --region "$REGION" \
                  --filters "Name=vpc-id,Values=$EXISTING_VPC" "Name=tag:Name,Values=$SUBNET_NAME_PATTERN" \
                  --query 'Subnets[0].SubnetId' \
                  --output text 2>/dev/null || echo "None")
                
                if [ "$SUBNET_ID" != "None" ] && [ ! -z "$SUBNET_ID" ]; then
                  TERRAFORM_RESOURCE="aws_route_table_association.${SUBNET_TYPE}[${TERRAFORM_INDEX}]"
                  
                  # Verificar si ya est√° en el estado
                  if terraform state show "$TERRAFORM_RESOURCE" >/dev/null 2>&1; then
                    echo "  ‚úÖ Route Table Association $SUBNET_TYPE[$TERRAFORM_INDEX] ya est√° en estado"
                  else
                    # Buscar la asociaci√≥n: obtener route table que tiene esta subnet
                    # Terraform requiere formato: subnet_id/route_table_id (NO RouteTableAssociationId)
                    RT_WITH_SUBNET=$(aws ec2 describe-route-tables \
                      --region "$REGION" \
                      --filters "Name=vpc-id,Values=$EXISTING_VPC" "Name=association.subnet-id,Values=$SUBNET_ID" \
                      --query 'RouteTables[0]' \
                      --output json 2>/dev/null || echo "{}")
                    
                    # Extraer RouteTableId usando jq
                    ROUTE_TABLE_ID=$(echo "$RT_WITH_SUBNET" | jq -r \
                      ".RouteTableId // empty" \
                      2>/dev/null || echo "")
                    
                    # Verificar que la asociaci√≥n existe y no es la main
                    IS_MAIN=$(echo "$RT_WITH_SUBNET" | jq -r \
                      ".Associations[]? | select(.SubnetId==\"$SUBNET_ID\") | .Main" \
                      2>/dev/null | head -n 1 || echo "true")
                    
                    if [ ! -z "$ROUTE_TABLE_ID" ] && [ "$ROUTE_TABLE_ID" != "null" ] && [ "$IS_MAIN" == "false" ]; then
                      # Formato correcto para Terraform: subnet_id/route_table_id
                      IMPORT_ID="${SUBNET_ID}/${ROUTE_TABLE_ID}"
                      echo "  üîÑ Importando Route Table Association: $IMPORT_ID"
                      echo "     (Subnet: $SUBNET_ID, Route Table: $ROUTE_TABLE_ID)"
                      
                      if terraform import "$TERRAFORM_RESOURCE" "$IMPORT_ID" 2>&1; then
                        echo "  ‚úÖ Route Table Association $SUBNET_TYPE[$TERRAFORM_INDEX] importada exitosamente"
                      else
                        echo "  ‚ö†Ô∏è  Error al importar, verificando estado..."
                        terraform state list | grep "$TERRAFORM_RESOURCE" || echo "     No encontrado en estado"
                      fi
                    else
                      if [ "$IS_MAIN" == "true" ]; then
                        echo "  ‚ÑπÔ∏è  La subnet $SUBNET_ID est√° asociada a la main route table (no necesita importaci√≥n)"
                      else
                        echo "  ‚ö†Ô∏è  No se pudo obtener RouteTableId para subnet $SUBNET_ID"
                        echo "     Verificando si la subnet tiene asociaci√≥n..."
                        HAS_ASSOC=$(aws ec2 describe-route-tables \
                          --region "$REGION" \
                          --filters "Name=association.subnet-id,Values=$SUBNET_ID" \
                          --query 'length(RouteTables)' \
                          --output text 2>/dev/null || echo "0")
                        if [ "$HAS_ASSOC" != "0" ] && [ "$HAS_ASSOC" != "None" ]; then
                          echo "     ‚ö†Ô∏è  La subnet S√ç tiene una asociaci√≥n, intentando m√©todo alternativo..."
                          # M√©todo alternativo: obtener todas las route tables y buscar
                          ALL_RT_JSON=$(aws ec2 describe-route-tables \
                            --region "$REGION" \
                            --filters "Name=vpc-id,Values=$EXISTING_VPC" \
                            --output json 2>/dev/null || echo "{}")
                          
                          # Buscar route table y subnet ID
                          RT_ID_ALT=$(echo "$ALL_RT_JSON" | jq -r \
                            ".RouteTables[] | select(.Associations[]?.SubnetId==\"$SUBNET_ID\" and .Associations[]?.Main==false) | .RouteTableId" \
                            2>/dev/null | head -n 1 || echo "None")
                          
                          if [ "$RT_ID_ALT" != "None" ] && [ ! -z "$RT_ID_ALT" ]; then
                            IMPORT_ID_ALT="${SUBNET_ID}/${RT_ID_ALT}"
                            echo "     ‚úÖ Route Table encontrada: $RT_ID_ALT, importando con formato: $IMPORT_ID_ALT"
                            terraform import "$TERRAFORM_RESOURCE" "$IMPORT_ID_ALT" 2>&1 || \
                              echo "     ‚ùå Fall√≥ la importaci√≥n alternativa"
                          else
                            echo "     ‚ùå No se pudo encontrar Route Table para esta subnet"
                          fi
                        else
                          echo "     ‚ÑπÔ∏è  La subnet no tiene asociaci√≥n, Terraform la crear√°"
                        fi
                      fi
                    fi
                  fi
                fi
              done
            done
            
            # Elastic IPs para NAT Gateways
            for EIP_INDEX in "0" "1"; do
              EIP_NAME="${PROJECT_NAME}-${ENV}-nat-eip-$((EIP_INDEX + 1))"
              EIP_ALLOC_ID=$(aws ec2 describe-addresses \
                --region "$REGION" \
                --filters "Name=tag:Name,Values=$EIP_NAME" \
                --query 'Addresses[0].AllocationId' \
                --output text 2>/dev/null || echo "None")
              
              if [ "$EIP_ALLOC_ID" != "None" ] && [ ! -z "$EIP_ALLOC_ID" ]; then
                TERRAFORM_RESOURCE="aws_eip.nat[${EIP_INDEX}]"
                if ! terraform state show "$TERRAFORM_RESOURCE" >/dev/null 2>&1; then
                  terraform import "$TERRAFORM_RESOURCE" "$EIP_ALLOC_ID" 2>&1 || \
                    echo "  ‚ö†Ô∏è  No se pudo importar Elastic IP $EIP_INDEX"
                fi
              fi
            done
            
            # NAT Gateways
            for NAT_INDEX in "0" "1"; do
              NAT_NAME="${PROJECT_NAME}-${ENV}-nat-$((NAT_INDEX + 1))"
              NAT_ID=$(aws ec2 describe-nat-gateways \
                --region "$REGION" \
                --filter "Name=vpc-id,Values=$EXISTING_VPC" "Name=state,Values=available,pending" \
                --query "NatGateways[${NAT_INDEX}].NatGatewayId" \
                --output text 2>/dev/null || echo "None")
              
              # Si no se encontr√≥ por √≠ndice, buscar por tags
              if [ "$NAT_ID" == "None" ] || [ -z "$NAT_ID" ]; then
                NAT_ID=$(aws ec2 describe-nat-gateways \
                  --region "$REGION" \
                  --filter "Name=vpc-id,Values=$EXISTING_VPC" "Name=tag:Name,Values=$NAT_NAME" "Name=state,Values=available,pending" \
                  --query 'NatGateways[0].NatGatewayId' \
                  --output text 2>/dev/null || echo "None")
              fi
              
              if [ "$NAT_ID" != "None" ] && [ ! -z "$NAT_ID" ]; then
                TERRAFORM_RESOURCE="aws_nat_gateway.main[${NAT_INDEX}]"
                if ! terraform state show "$TERRAFORM_RESOURCE" >/dev/null 2>&1; then
                  echo "  üîÑ Importando NAT Gateway $NAT_ID..."
                  terraform import "$TERRAFORM_RESOURCE" "$NAT_ID" 2>&1 || \
                    echo "  ‚ö†Ô∏è  No se pudo importar NAT Gateway $NAT_INDEX"
                else
                  echo "  ‚úÖ NAT Gateway $NAT_INDEX ya est√° en estado"
                fi
              fi
            done
            
            echo "‚úÖ Recursos relacionados de VPC importados (o ya en estado)"
          else
            echo "‚úÖ VPC no existe, Terraform la crear√°"
          fi
          
          # Importar DB Subnet Group si existe
          DB_SUBNET_GROUP_NAME="${PROJECT_NAME}-${ENV}-db-subnet-group"
          if aws rds describe-db-subnet-groups --db-subnet-group-name "$DB_SUBNET_GROUP_NAME" --region "$REGION" >/dev/null 2>&1; then
            echo "üì¶ DB Subnet Group existe: $DB_SUBNET_GROUP_NAME"
            
            # Verificar si ya est√° en el estado de Terraform
            if terraform state show aws_db_subnet_group.main >/dev/null 2>&1; then
              echo "‚úÖ DB Subnet Group ya est√° en el estado de Terraform"
            else
              echo "üîÑ Importando DB Subnet Group al estado de Terraform..."
              
              # Importar el recurso
              if terraform import aws_db_subnet_group.main "$DB_SUBNET_GROUP_NAME" 2>&1; then
                echo "‚úÖ DB Subnet Group importado exitosamente"
                
                # Verificar que las subnets coinciden (opcional, solo para logging)
                EXISTING_SUBNETS=$(aws rds describe-db-subnet-groups \
                  --db-subnet-group-name "$DB_SUBNET_GROUP_NAME" \
                  --region "$REGION" \
                  --query 'DBSubnetGroups[0].Subnets[].SubnetIdentifier' \
                  --output text | tr '\t' ' ')
                echo "‚ÑπÔ∏è  Subnets en DB Subnet Group existente: $EXISTING_SUBNETS"
                echo "‚ÑπÔ∏è  Terraform verificar√° que las subnets coincidan en el plan"
              else
                echo "‚ö†Ô∏è  No se pudo importar (puede ser por diferencias en configuraci√≥n)"
                echo "‚ÑπÔ∏è  Terraform intentar√° crear uno nuevo o actualizar el existente"
              fi
            fi
          else
            echo "‚úÖ DB Subnet Group no existe, Terraform lo crear√°"
          fi
          
          # Importar DynamoDB Table si existe
          TABLE_NAME="${PROJECT_NAME}-${ENV}-appointments"
          if aws dynamodb describe-table --table-name "$TABLE_NAME" --region "$REGION" >/dev/null 2>&1; then
            echo "üì¶ DynamoDB Table existe: $TABLE_NAME"
            if terraform state show aws_dynamodb_table.appointments >/dev/null 2>&1; then
              echo "‚úÖ DynamoDB Table ya est√° en el estado de Terraform"
            else
              echo "üîÑ Importando DynamoDB Table..."
              terraform import aws_dynamodb_table.appointments "$TABLE_NAME" 2>&1 || \
                echo "‚ö†Ô∏è  No se pudo importar (continuando...)"
            fi
          else
            echo "‚úÖ DynamoDB Table no existe, Terraform la crear√°"
          fi
          
          # Importar EventBridge Bus si existe
          BUS_NAME="${PROJECT_NAME}-${ENV}-bus"
          if aws events describe-event-bus --name "$BUS_NAME" --region "$REGION" >/dev/null 2>&1; then
            echo "üì¶ EventBridge Bus existe: $BUS_NAME"
            if terraform state show aws_cloudwatch_event_bus.main >/dev/null 2>&1; then
              echo "‚úÖ EventBridge Bus ya est√° en el estado de Terraform"
            else
              echo "üîÑ Importando EventBridge Bus..."
              terraform import aws_cloudwatch_event_bus.main "$BUS_NAME" 2>&1 || \
                echo "‚ö†Ô∏è  No se pudo importar (continuando...)"
            fi
          else
            echo "‚úÖ EventBridge Bus no existe, Terraform lo crear√°"
          fi
          
          # Importar Secrets Manager si existen
          SECRETS=(
            "${PROJECT_NAME}-${ENV}-rds-peru-credentials"
            "${PROJECT_NAME}-${ENV}-rds-chile-credentials"
          )
          
          for SECRET_NAME in "${SECRETS[@]}"; do
            if aws secretsmanager describe-secret --secret-id "$SECRET_NAME" --region "$REGION" >/dev/null 2>&1; then
              echo "üì¶ Secret existe: $SECRET_NAME"
              
              # Determinar el nombre del recurso en Terraform
              if [[ "$SECRET_NAME" == *"peru"* ]]; then
                TERRAFORM_RESOURCE="aws_secretsmanager_secret.rds_peru"
              else
                TERRAFORM_RESOURCE="aws_secretsmanager_secret.rds_chile"
              fi
              
              if terraform state show "$TERRAFORM_RESOURCE" >/dev/null 2>&1; then
                echo "‚úÖ Secret ya est√° en el estado de Terraform"
              else
                echo "üîÑ Importando Secret..."
                terraform import "$TERRAFORM_RESOURCE" "$SECRET_NAME" 2>&1 || \
                  echo "‚ö†Ô∏è  No se pudo importar (continuando...)"
              fi
            else
              echo "‚úÖ Secret $SECRET_NAME no existe, Terraform lo crear√°"
            fi
          done
          
          # Importar RDS Instances si existen
          RDS_INSTANCES=(
            "${PROJECT_NAME}-${ENV}-rds-pe"
            "${PROJECT_NAME}-${ENV}-rds-cl"
          )
          
          for RDS_INSTANCE_ID in "${RDS_INSTANCES[@]}"; do
            if aws rds describe-db-instances --db-instance-identifier "$RDS_INSTANCE_ID" --region "$REGION" >/dev/null 2>&1; then
              echo "üì¶ RDS Instance existe: $RDS_INSTANCE_ID"
              
              # Determinar el nombre del recurso en Terraform
              if [[ "$RDS_INSTANCE_ID" == *"pe"* ]]; then
                TERRAFORM_RESOURCE="aws_db_instance.peru"
              else
                TERRAFORM_RESOURCE="aws_db_instance.chile"
              fi
              
              if terraform state show "$TERRAFORM_RESOURCE" >/dev/null 2>&1; then
                echo "‚úÖ RDS Instance ya est√° en el estado de Terraform"
              else
                echo "üîÑ Importando RDS Instance..."
                terraform import "$TERRAFORM_RESOURCE" "$RDS_INSTANCE_ID" 2>&1 || \
                  echo "‚ö†Ô∏è  No se pudo importar (continuando...)"
              fi
            else
              echo "‚úÖ RDS Instance $RDS_INSTANCE_ID no existe, Terraform la crear√°"
            fi
          done
          
          echo "‚úÖ Proceso de importaci√≥n completado"

      - name: Terraform Plan (after import)
        if: github.event_name == 'push' || github.event_name == 'workflow_dispatch'
        working-directory: ./terraform
        run: |
          # Crear plan DESPU√âS de la importaci√≥n para incluir recursos importados
          terraform plan \
            -var="environment=${{ steps.determine-env.outputs.environment }}" \
            -var="rds_pe_master_username=${{ secrets.RDS_PE_USERNAME }}" \
            -var="rds_pe_master_password=${{ secrets.RDS_PE_PASSWORD }}" \
            -var="rds_cl_master_username=${{ secrets.RDS_CL_USERNAME }}" \
            -var="rds_cl_master_password=${{ secrets.RDS_CL_PASSWORD }}" \
            -out=tfplan

      - name: Wait for RDS Instances to be Available
        if: github.event_name == 'push' || github.event_name == 'workflow_dispatch'
        run: |
          ENV="${{ steps.determine-env.outputs.environment }}"
          PROJECT_NAME="agendamiento-v2"
          REGION="us-east-1"
          
          RDS_INSTANCES=(
            "${PROJECT_NAME}-${ENV}-rds-pe"
            "${PROJECT_NAME}-${ENV}-rds-cl"
          )
          
          for RDS_INSTANCE_ID in "${RDS_INSTANCES[@]}"; do
            echo "‚è≥ Esperando a que la instancia RDS $RDS_INSTANCE_ID est√© disponible..."
            
            # Verificar si la instancia existe
            if aws rds describe-db-instances --db-instance-identifier "$RDS_INSTANCE_ID" --region "$REGION" >/dev/null 2>&1; then
              # Esperar hasta que la instancia est√© en estado "available"
              MAX_ATTEMPTS=30
              ATTEMPT=0
              
              while [ $ATTEMPT -lt $MAX_ATTEMPTS ]; do
                STATUS=$(aws rds describe-db-instances \
                  --db-instance-identifier "$RDS_INSTANCE_ID" \
                  --region "$REGION" \
                  --query 'DBInstances[0].DBInstanceStatus' \
                  --output text 2>/dev/null || echo "unknown")
                
                echo "  Estado actual: $STATUS (intento $((ATTEMPT + 1))/$MAX_ATTEMPTS)"
                
                if [ "$STATUS" == "available" ]; then
                  echo "‚úÖ Instancia $RDS_INSTANCE_ID est√° disponible"
                  break
                elif [ "$STATUS" == "modifying" ] || [ "$STATUS" == "backing-up" ] || [ "$STATUS" == "upgrading" ]; then
                  echo "  ‚è≥ Instancia en proceso ($STATUS), esperando 30 segundos..."
                  sleep 30
                  ATTEMPT=$((ATTEMPT + 1))
                else
                  echo "  ‚ö†Ô∏è  Estado inesperado: $STATUS"
                  # Continuar de todas formas si no es un estado cr√≠tico
                  if [ "$STATUS" != "unknown" ]; then
                    break
                  fi
                  sleep 10
                  ATTEMPT=$((ATTEMPT + 1))
                fi
              done
              
              if [ $ATTEMPT -eq $MAX_ATTEMPTS ]; then
                echo "‚ö†Ô∏è  Timeout esperando a que $RDS_INSTANCE_ID est√© disponible"
                echo "   Continuando de todas formas..."
              fi
            else
              echo "‚ÑπÔ∏è  Instancia $RDS_INSTANCE_ID no existe, ser√° creada por Terraform"
            fi
          done
          
          echo "‚úÖ Verificaci√≥n de instancias RDS completada"

      - name: Terraform Apply
        if: github.event_name == 'push' || github.event_name == 'workflow_dispatch'
        working-directory: ./terraform
        run: |
          # Aplicar el plan creado DESPU√âS de la importaci√≥n (incluye recursos importados)
          terraform apply -auto-approve tfplan

      - name: Get Terraform Outputs
        id: tf-outputs
        if: github.event_name == 'push' || github.event_name == 'workflow_dispatch'
        working-directory: ./terraform
        run: |
          # Verificar que el state tiene outputs
          if ! terraform output vpc_id > /dev/null 2>&1; then
            echo "‚ùå Error: Terraform outputs no est√°n disponibles"
            echo "Esto puede ocurrir si Terraform apply fall√≥"
            exit 1
          fi
          
          # Obtener outputs
          echo "vpc_id=$(terraform output -raw vpc_id)" >> $GITHUB_OUTPUT
          # private_subnet_ids es una lista, usar -json y convertir a string separado por comas
          PRIVATE_SUBNETS=$(terraform output -json private_subnet_ids | jq -r 'join(",")')
          echo "private_subnet_ids=$PRIVATE_SUBNETS" >> $GITHUB_OUTPUT
          echo "lambda_sg_id=$(terraform output -raw lambda_security_group_id)" >> $GITHUB_OUTPUT
          echo "dynamodb_table=$(terraform output -raw dynamodb_table_name)" >> $GITHUB_OUTPUT
          echo "dynamodb_table_arn=$(terraform output -raw dynamodb_table_arn)" >> $GITHUB_OUTPUT
          echo "sns_peru_arn=$(terraform output -raw sns_topic_arn_peru)" >> $GITHUB_OUTPUT
          echo "sns_chile_arn=$(terraform output -raw sns_topic_arn_chile)" >> $GITHUB_OUTPUT
          echo "sqs_queue_url_peru=$(terraform output -raw sqs_queue_url_peru)" >> $GITHUB_OUTPUT
          echo "sqs_queue_url_chile=$(terraform output -raw sqs_queue_url_chile)" >> $GITHUB_OUTPUT
          echo "sqs_queue_arn_peru=$(terraform output -raw sqs_queue_arn_peru)" >> $GITHUB_OUTPUT
          echo "sqs_queue_arn_chile=$(terraform output -raw sqs_queue_arn_chile)" >> $GITHUB_OUTPUT
          echo "sqs_completion_queue_url=$(terraform output -raw sqs_completion_queue_url)" >> $GITHUB_OUTPUT
          echo "sqs_completion_queue_arn=$(terraform output -raw sqs_completion_queue_arn)" >> $GITHUB_OUTPUT
          echo "eventbridge_bus_name=$(terraform output -raw eventbridge_bus_name)" >> $GITHUB_OUTPUT
          echo "rds_peru_secret_arn=$(terraform output -raw rds_peru_secret_arn)" >> $GITHUB_OUTPUT
          echo "rds_chile_secret_arn=$(terraform output -raw rds_chile_secret_arn)" >> $GITHUB_OUTPUT
          
          # Mostrar outputs para debug
          echo "‚úÖ Terraform outputs obtenidos correctamente"
          echo "VPC ID: $(terraform output -raw vpc_id)"

  # ===============================================
  # Deploy Lambda Functions (SAM)
  # ===============================================
  deploy-sam:
    name: Deploy Lambda Functions (SAM)
    needs: [test-and-build, deploy-terraform]
    runs-on: ubuntu-latest
    if: github.event_name == 'push' || github.event_name == 'workflow_dispatch'
    environment: 
      name: ${{ github.ref == 'refs/heads/main' && 'prod' || github.ref == 'refs/heads/develop' && 'staging' || 'dev' }}
    
    outputs:
      api_url: ${{ steps.sam-deploy.outputs.api_url }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: package-lock.json

      - name: Download build artifacts
        uses: actions/download-artifact@v4
        with:
          name: dist
          path: dist/

      - name: Setup AWS SAM
        uses: aws-actions/setup-sam@v2
        with:
          use-installer: true

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Determine environment
        id: determine-env
        run: |
          if [[ "${{ github.ref }}" == "refs/heads/main" ]]; then
            echo "environment=prod" >> $GITHUB_OUTPUT
          elif [[ "${{ github.ref }}" == "refs/heads/develop" ]]; then
            echo "environment=staging" >> $GITHUB_OUTPUT
          else
            echo "environment=dev" >> $GITHUB_OUTPUT
          fi

      - name: Prepare Lambda Package
        run: |
          echo "üì¶ Preparando paquete Lambda..."
          echo "üîç Verificando estructura del proyecto..."
          
          # Verificar que dist/ existe
          if [ ! -d "dist" ]; then
            echo "‚ùå Error: directorio dist/ no encontrado"
            echo "   Ejecutando build..."
            npm run build
          else
            echo "‚úÖ directorio dist/ encontrado"
          fi
          
          # Copiar node_modules a dist/ para que est√© disponible en Lambda
          echo "üìÇ Copiando node_modules a dist/..."
          cp -r node_modules dist/
          echo "‚úÖ node_modules copiado a dist/"
          
          # Copiar package.json a dist/
          echo "üìÇ Copiando package.json a dist/..."
          cp package.json dist/
          echo "‚úÖ package.json copiado a dist/"
          
          echo "‚úÖ Paquete Lambda preparado"

      - name: SAM Build
        working-directory: ./sam
        run: |
          echo "üî® Ejecutando SAM Build..."
          echo "üì¶ CodeUri apunta a dist/ (c√≥digo compilado + node_modules)"
          
          # Ejecutar sam build
          sam build
          
          echo ""
          echo "‚úÖ SAM Build completado"
          echo "üìã Verificando estructura del build..."
          if [ -d ".aws-sam/build" ]; then
            echo "üìÅ Directorio de build encontrado"
            # Verificar que node_modules est√° presente en el build
            NODE_MODULES_COUNT=$(find .aws-sam/build -name "node_modules" -type d | wc -l)
            if [ "$NODE_MODULES_COUNT" -gt 0 ]; then
              echo "‚úÖ node_modules encontrado en build ($NODE_MODULES_COUNT ubicaciones)"
            else
              echo "‚ö†Ô∏è  node_modules no encontrado en build - esto causar√° errores"
              echo "   Listando estructura del build:"
              find .aws-sam/build -maxdepth 3 -type d | head -10
            fi
            # Verificar que handler.js existe
            HANDLER_COUNT=$(find .aws-sam/build -name "handler.js" -path "*/appointment/*" | wc -l)
            if [ "$HANDLER_COUNT" -gt 0 ]; then
              echo "‚úÖ handler.js encontrado ($HANDLER_COUNT archivos)"
            else
              echo "‚ö†Ô∏è  handler.js no encontrado"
              echo "   Buscando archivos .js en build:"
              find .aws-sam/build -name "*.js" -path "*/appointment/*" | head -5
            fi
          fi

      - name: Validate SAM Parameters
        run: |
          echo "üîç Validando par√°metros para SAM Deploy..."
          
          VPC_ID="${{ needs.deploy-terraform.outputs.vpc_id }}"
          SUBNETS="${{ needs.deploy-terraform.outputs.private_subnet_ids }}"
          SG_ID="${{ needs.deploy-terraform.outputs.lambda_sg_id }}"
          
          echo "VPC ID: $VPC_ID"
          echo "Private Subnets: $SUBNETS"
          echo "Security Group: $SG_ID"
          
          # Verificar VPC
          if ! aws ec2 describe-vpcs --vpc-ids "$VPC_ID" --region ${{ env.AWS_REGION }} >/dev/null 2>&1; then
            echo "‚ùå VPC $VPC_ID no existe"
            exit 1
          fi
          echo "‚úÖ VPC existe"
          
          # Verificar Security Group
          if ! aws ec2 describe-security-groups --group-ids "$SG_ID" --region ${{ env.AWS_REGION }} >/dev/null 2>&1; then
            echo "‚ùå Security Group $SG_ID no existe"
            exit 1
          fi
          echo "‚úÖ Security Group existe"
          
          # Verificar Subnets
          IFS=',' read -ra SUBNET_ARRAY <<< "$SUBNETS"
          for SUBNET in "${SUBNET_ARRAY[@]}"; do
            if ! aws ec2 describe-subnets --subnet-ids "$SUBNET" --region ${{ env.AWS_REGION }} >/dev/null 2>&1; then
              echo "‚ùå Subnet $SUBNET no existe"
              exit 1
            fi
            echo "‚úÖ Subnet $SUBNET existe"
          done
          
          echo "‚úÖ Todos los recursos de red validados correctamente"

      - name: Check and Fix CloudFormation Stack State
        continue-on-error: false
        run: |
          STACK_NAME="agendamiento-citas-${{ steps.determine-env.outputs.environment }}"
          REGION="${{ env.AWS_REGION }}"
          
          echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
          echo "üîç Verificando estado del stack: $STACK_NAME"
          echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
          
          # Obtener estado del stack
          STACK_STATUS=$(aws cloudformation describe-stacks \
            --stack-name "$STACK_NAME" \
            --region "$REGION" \
            --query 'Stacks[0].StackStatus' \
            --output text 2>/dev/null || echo "DOES_NOT_EXIST")
          
          echo "üìä Estado actual: $STACK_STATUS"
          
          # Si el stack est√° siendo eliminado, esperar un poco m√°s
          if [ "$STACK_STATUS" == "DELETE_IN_PROGRESS" ]; then
            echo ""
            echo "‚è≥ Stack en proceso de eliminaci√≥n..."
            echo "   Esperando hasta 5 minutos adicionales para que termine..."
            WAIT_ELAPSED=0
            MAX_DELETE_WAIT=300  # 5 minutos adicionales
            while [ $WAIT_ELAPSED -lt $MAX_DELETE_WAIT ]; do
              sleep 30
              WAIT_ELAPSED=$((WAIT_ELAPSED + 30))
              STACK_STATUS=$(aws cloudformation describe-stacks \
                --stack-name "$STACK_NAME" \
                --region "$REGION" \
                --query 'Stacks[0].StackStatus' \
                --output text 2>/dev/null || echo "DELETED")
              
              if [ "$STACK_STATUS" == "DELETED" ] || [ "$STACK_STATUS" == "DOES_NOT_EXIST" ]; then
                echo "‚úÖ Stack eliminado completamente"
                STACK_STATUS="DOES_NOT_EXIST"
                break
              elif [ "$STACK_STATUS" != "DELETE_IN_PROGRESS" ]; then
                echo "‚ö†Ô∏è  Estado cambi√≥ a: $STACK_STATUS"
                break
              fi
              echo "  ‚è≥ A√∫n eliminando... (${WAIT_ELAPSED}s)"
            done
            
            if [ "$STACK_STATUS" == "DELETE_IN_PROGRESS" ]; then
              echo "‚ö†Ô∏è  Stack a√∫n en DELETE_IN_PROGRESS despu√©s de espera adicional"
              echo "   Continuando - el deploy intentar√° crear el stack"
              echo "   Si falla por conflicto, el siguiente deploy lo manejar√°"
            fi
          fi
          
          # Estados que requieren eliminaci√≥n del stack
          FAILED_STATES=("ROLLBACK_IN_PROGRESS" "ROLLBACK_COMPLETE" "ROLLBACK_FAILED" "DELETE_FAILED" "CREATE_FAILED" "UPDATE_ROLLBACK_IN_PROGRESS" "UPDATE_ROLLBACK_COMPLETE" "UPDATE_ROLLBACK_FAILED")
          
          if [[ " ${FAILED_STATES[@]} " =~ " ${STACK_STATUS} " ]]; then
            echo ""
            echo "‚ö†Ô∏è  ¬°ATENCI√ìN! Stack en estado fallido: $STACK_STATUS"
            echo "üóëÔ∏è  Eliminando stack autom√°ticamente para permitir nuevo deploy..."
            echo ""
            
            # Mostrar recursos del stack antes de eliminar
            echo "üìã Recursos en el stack:"
            aws cloudformation list-stack-resources \
              --stack-name "$STACK_NAME" \
              --region "$REGION" \
              --query 'StackResourceSummaries[*].[LogicalResourceId,ResourceType,ResourceStatus]' \
              --output table 2>/dev/null || echo "No se pudieron listar recursos"
            
            echo ""
            echo "üîÑ Iniciando eliminaci√≥n del stack..."
            # Intentar eliminar el stack
            if aws cloudformation delete-stack \
              --stack-name "$STACK_NAME" \
              --region "$REGION"; then
              echo "‚úÖ Comando de eliminaci√≥n enviado exitosamente"
            else
              echo "‚ùå Error al enviar comando de eliminaci√≥n"
              exit 1
            fi
            
            echo "‚è≥ Esperando a que el stack se elimine completamente (m√°ximo 20 minutos)..."
            echo "üìù Lambda en VPC puede tardar 15-20 minutos en eliminarse (ENIs, IPs privadas)"
            echo ""
            
            # Esperar a que el stack se elimine (m√°ximo 20 minutos para Lambda en VPC)
            MAX_WAIT=1200  # 20 minutos
            ELAPSED=0
            DOTS=0
            while [ $ELAPSED -lt $MAX_WAIT ]; do
              CURRENT_STATUS=$(aws cloudformation describe-stacks \
                --stack-name "$STACK_NAME" \
                --region "$REGION" \
                --query 'Stacks[0].StackStatus' \
                --output text 2>/dev/null || echo "DELETED")
              
              if [ "$CURRENT_STATUS" == "DELETED" ]; then
                echo ""
                echo "‚úÖ Stack eliminado exitosamente en ${ELAPSED}s"
                echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
                break
              elif [ "$CURRENT_STATUS" == "DELETE_FAILED" ]; then
                echo ""
                echo "‚ùå Error al eliminar stack - Estado: DELETE_FAILED"
                echo "Mostrando eventos del stack:"
                aws cloudformation describe-stack-events \
                  --stack-name "$STACK_NAME" \
                  --max-items 10 \
                  --region "$REGION" \
                  --query 'StackEvents[*].[Timestamp,ResourceStatus,ResourceStatusReason]' \
                  --output table 2>/dev/null || true
                echo "üí° Intenta eliminarlo manualmente desde la consola de AWS"
                exit 1
              elif [ "$CURRENT_STATUS" == "DELETE_IN_PROGRESS" ]; then
                # Mostrar progreso cada 5 minutos (20 * 15s)
                printf "."
                DOTS=$((DOTS + 1))
                if [ $DOTS -eq 20 ]; then  # Cada 5 minutos (20 * 15s = 300s)
                  echo ""
                  echo "  ‚è≥ Eliminaci√≥n en progreso... ${ELAPSED}s (Lambda en VPC puede tardar)"
                  DOTS=0
                fi
              else
                echo "  Estado: $CURRENT_STATUS (esperando... ${ELAPSED}s)"
              fi
              
              sleep 15
              ELAPSED=$((ELAPSED + 15))
            done
            
            # Si alcanzamos el timeout, verificar estado final
            if [ $ELAPSED -ge $MAX_WAIT ]; then
              FINAL_STATUS=$(aws cloudformation describe-stacks \
                --stack-name "$STACK_NAME" \
                --region "$REGION" \
                --query 'Stacks[0].StackStatus' \
                --output text 2>/dev/null || echo "DELETED")
              
              if [ "$FINAL_STATUS" == "DELETED" ]; then
                echo ""
                echo "‚úÖ Stack eliminado exitosamente (justo antes del timeout)"
                echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
              elif [ "$FINAL_STATUS" == "DELETE_IN_PROGRESS" ]; then
                echo ""
                echo "‚ö†Ô∏è  Timeout alcanzado, pero stack a√∫n en DELETE_IN_PROGRESS"
                echo "   Esto es normal para Lambda en VPC (puede tardar hasta 20+ minutos)"
                echo "   El siguiente deploy esperar√° o intentar√° eliminar nuevamente"
                echo "   Continuando con el deploy..."
                echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
                # NO salir con error - permitir que el deploy contin√∫e
                # El siguiente paso (Check and Fix) manejar√° esto
              else
                echo ""
                echo "‚ùå Stack en estado inesperado: $FINAL_STATUS"
                echo "   Verifica manualmente en la consola de AWS"
                exit 1
              fi
            fi
            
            # Peque√±a espera adicional para asegurar que AWS est√© listo
            echo "‚è∏Ô∏è  Esperando 5s adicionales para asegurar que AWS est√© listo..."
            sleep 5
            echo "‚úÖ Listo para crear nuevo stack"
            
          elif [ "$STACK_STATUS" == "DOES_NOT_EXIST" ]; then
            echo "‚úÖ Stack no existe, se crear√° uno nuevo"
            echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
          else
            echo "‚úÖ Stack en estado v√°lido: $STACK_STATUS"
            echo "   No se requiere acci√≥n de limpieza"
            echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
          fi

      - name: SAM Deploy
        working-directory: ./sam
        timeout-minutes: 30
        run: |
          echo "üöÄ Iniciando SAM Deploy..."
          echo "‚è±Ô∏è  Timeout configurado: 30 minutos"
          echo "üìù Lambda en VPC puede tardar 10-15 minutos en primera creaci√≥n"
          echo ""
          
          set +e  # No salir inmediatamente en error
          sam deploy \
            --stack-name agendamiento-citas-${{ steps.determine-env.outputs.environment }} \
            --resolve-s3 \
            --parameter-overrides \
              Environment=${{ steps.determine-env.outputs.environment }} \
              VpcId=${{ needs.deploy-terraform.outputs.vpc_id }} \
              PrivateSubnetIds="${{ needs.deploy-terraform.outputs.private_subnet_ids }}" \
              LambdaSecurityGroupId=${{ needs.deploy-terraform.outputs.lambda_sg_id }} \
              DynamoDBTableName=${{ needs.deploy-terraform.outputs.dynamodb_table }} \
              DynamoDBTableArn=${{ needs.deploy-terraform.outputs.dynamodb_table_arn }} \
              SNSTopicArnPeru=${{ needs.deploy-terraform.outputs.sns_peru_arn }} \
              SNSTopicArnChile=${{ needs.deploy-terraform.outputs.sns_chile_arn }} \
              SQSQueueUrlPeru=${{ needs.deploy-terraform.outputs.sqs_queue_url_peru }} \
              SQSQueueUrlChile=${{ needs.deploy-terraform.outputs.sqs_queue_url_chile }} \
              SQSQueueArnPeru=${{ needs.deploy-terraform.outputs.sqs_queue_arn_peru }} \
              SQSQueueArnChile=${{ needs.deploy-terraform.outputs.sqs_queue_arn_chile }} \
              SQSCompletionQueueUrl=${{ needs.deploy-terraform.outputs.sqs_completion_queue_url }} \
              SQSCompletionQueueArn=${{ needs.deploy-terraform.outputs.sqs_completion_queue_arn }} \
              EventBridgeBusName=${{ needs.deploy-terraform.outputs.eventbridge_bus_name }} \
              RDSPeruSecretArn=${{ needs.deploy-terraform.outputs.rds_peru_secret_arn }} \
              RDSChileSecretArn=${{ needs.deploy-terraform.outputs.rds_chile_secret_arn }} \
            --capabilities CAPABILITY_IAM \
            --no-confirm-changeset \
            --no-fail-on-empty-changeset \
            --disable-rollback \
            --debug
          
          SAM_EXIT_CODE=$?
          set -e  # Reactivar salir en error
          
          if [ $SAM_EXIT_CODE -ne 0 ]; then
            echo ""
            echo "‚ùå SAM Deploy fall√≥ con c√≥digo: $SAM_EXIT_CODE"
            echo ""
            echo "üìã Mostrando eventos de CloudFormation para debugging:"
            aws cloudformation describe-stack-events \
              --stack-name agendamiento-citas-${{ steps.determine-env.outputs.environment }} \
              --max-items 30 \
              --region ${{ env.AWS_REGION }} \
              --query 'StackEvents[?ResourceStatus==`CREATE_FAILED` || contains(ResourceStatus, `ROLLBACK`)][].{Time:Timestamp,Resource:LogicalResourceId,Type:ResourceType,Status:ResourceStatus,Reason:ResourceStatusReason}' \
              --output table 2>/dev/null || echo "No se pudieron obtener eventos"
            exit 1
          fi
          
          echo ""
          echo "‚úÖ SAM Deploy completado exitosamente"

      - name: Get API URL
        id: sam-deploy
        run: |
          STACK_NAME="agendamiento-citas-${{ steps.determine-env.outputs.environment }}"
          
          echo "üîç Obteniendo API URL del stack: $STACK_NAME"
          
          # Esperar a que el stack est√© completamente actualizado
          sleep 10
          
          # Get API URL
          API_URL=$(aws cloudformation describe-stacks \
            --stack-name "$STACK_NAME" \
            --region ${{ env.AWS_REGION }} \
            --query 'Stacks[0].Outputs[?OutputKey==`ApiUrl`].OutputValue' \
            --output text)
          
          if [ -z "$API_URL" ] || [ "$API_URL" == "None" ]; then
            echo "‚ùå No se pudo obtener API URL"
            echo "Verificando outputs del stack..."
            aws cloudformation describe-stacks \
              --stack-name "$STACK_NAME" \
              --region ${{ env.AWS_REGION }} \
              --query 'Stacks[0].Outputs' || true
            exit 1
          fi
          
          echo "‚úÖ API URL obtenida: $API_URL"
          echo "api_url=$API_URL" >> $GITHUB_OUTPUT

      - name: Show CloudFormation Events on Failure
        if: failure()
        run: |
          STACK_NAME="agendamiento-citas-${{ steps.determine-env.outputs.environment }}"
          echo "‚ùå SAM Deploy fall√≥. Mostrando eventos de CloudFormation..."
          echo ""
          
          # Obtener los √∫ltimos 20 eventos del stack
          aws cloudformation describe-stack-events \
            --stack-name "$STACK_NAME" \
            --max-items 20 \
            --query 'StackEvents[].[Timestamp,LogicalResourceId,ResourceType,ResourceStatus,ResourceStatusReason]' \
            --output table 2>/dev/null || echo "No se pudieron obtener eventos del stack"
          
          echo ""
          echo "üí° Buscar eventos con status 'FAILED' arriba para identificar la causa"

      - name: Display API URL
        if: success()
        run: |
          echo "üöÄ API deployed successfully!"
          echo "üìç API URL: ${{ steps.sam-deploy.outputs.api_url }}"

  # ===============================================
  # Initialize Databases
  # ===============================================
  init-databases:
    name: Initialize RDS Databases
    needs: [deploy-terraform]
    runs-on: ubuntu-latest
    if: false  # Deshabilitado: La inicializaci√≥n de DB se har√° manualmente
    # Raz√≥n: Requiere que las instancias RDS est√©n completamente listas para aceptar conexiones
    # y que los endpoints est√©n configurados como secrets
    # Original: github.event_name == 'push' && (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/develop')
    continue-on-error: true  # No fallar el deploy si este paso falla
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Install MySQL Client
        run: |
          sudo apt-get update
          sudo apt-get install -y mysql-client

      - name: Initialize Peru Database
        run: |
          mysql -h ${{ secrets.RDS_PE_HOST }} \
                -u ${{ secrets.RDS_PE_USERNAME }} \
                -p${{ secrets.RDS_PE_PASSWORD }} \
                ${{ secrets.RDS_PE_DATABASE }} \
                < docs/database-schema.sql

      - name: Initialize Chile Database
        run: |
          mysql -h ${{ secrets.RDS_CL_HOST }} \
                -u ${{ secrets.RDS_CL_USERNAME }} \
                -p${{ secrets.RDS_CL_PASSWORD }} \
                ${{ secrets.RDS_CL_DATABASE }} \
                < docs/database-schema.sql

  # ===============================================
  # Integration Tests
  # ===============================================
  integration-tests:
    name: Integration Tests
    needs: [deploy-sam]
    runs-on: ubuntu-latest
    if: false  # Deshabilitado temporalmente - Implementar tests reales
    # Los tests b√°sicos de curl no son suficientes sin DB inicializada
    # Habilitar cuando: 1) DB est√© inicializada, 2) Tests reales implementados
    continue-on-error: true
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Test API - Create Appointment
        run: |
          API_URL="${{ needs.deploy-sam.outputs.api_url }}"
          
          RESPONSE=$(curl -s -X POST "$API_URL/appointments" \
            -H "Content-Type: application/json" \
            -d '{"insuredId": "12345", "scheduleId": 100, "countryISO": "PE"}')
          
          echo "Response: $RESPONSE"
          
          # Verificar que la respuesta contiene appointmentId
          if echo "$RESPONSE" | jq -e '.appointmentId' > /dev/null; then
            echo "‚úÖ Create appointment test passed"
          else
            echo "‚ùå Create appointment test failed"
            exit 1
          fi

      - name: Test API - List Appointments
        run: |
          API_URL="${{ needs.deploy-sam.outputs.api_url }}"
          
          RESPONSE=$(curl -s "$API_URL/appointments/12345")
          
          echo "Response: $RESPONSE"
          
          # Verificar que la respuesta contiene appointments
          if echo "$RESPONSE" | jq -e '.appointments' > /dev/null; then
            echo "‚úÖ List appointments test passed"
          else
            echo "‚ùå List appointments test failed"
            exit 1
          fi

  # ===============================================
  # Notification
  # ===============================================
  notify:
    name: Send Notification
    needs: [deploy-sam]
    runs-on: ubuntu-latest
    if: always() && (github.event_name == 'push' || github.event_name == 'workflow_dispatch')
    
    steps:
      - name: Send success notification
        if: needs.deploy-sam.result == 'success'
        run: |
          echo "‚úÖ Deployment successful!"
          echo "üöÄ API URL: ${{ needs.deploy-sam.outputs.api_url }}"
          echo "üåç Environment: ${{ github.ref }}"
          echo ""
          echo "üìù Pr√≥ximos pasos:"
          echo "   1. Ejecutar workflow 'Database Migrations' para inicializar DBs"
          echo "   2. Probar endpoints de la API"
          echo "   3. Habilitar integration tests cuando DB est√© lista"

      - name: Send failure notification
        if: needs.deploy-sam.result != 'success'
        run: |
          echo "‚ùå Deployment failed!"
          echo "üîç Check the logs for details"

